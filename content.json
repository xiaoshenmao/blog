[{"title":"hexo-个人博客的搭建","date":"2017-08-18T06:38:39.000Z","path":"2017/08/18/2017-08-18-hexoInitYourBlog/","text":"经过各种找资料，踩过各种坑，终于使用 hexo 搭建个人博客初步完成了，域名目前用得时 github 的，我的 hexo 是 3.1.1 版本，hexo 不同的版本，很多配置都不一样。好吧，废话不多说了，开始吧。 本篇文章累计了大量评论，和我的一些解答，读者有什么问题可以先看看评论，或者搜下关键字，如果还是有问题可以给我在评论里给我留言，问题很着急的可以加我 ＱＱ：78233332 ，或者给我发邮件：hello_sorrow@163.com 正文： 这边教程是针对与Mac的，参考链接，由于原文讲到的hexo是以前的老版本，所以现在的版本配置的时候会有些改动。 之前是想着写博客，一方面是给自己做笔记，可以提升自己的写作、总结能力，一个技术点我们会使用，并不难，但是要做到让让别人也能听懂我们讲得，还是需要一定的技巧和经验的。很多类似于CSDN、博客园也都可以写文章，但是页面的样式我，不是太喜欢，简书还算好点得。最近看到一些大神们的博客（在我的友情链接里有），貌似都是用hexo写得，我也依葫芦画瓢的搭建了一个。不罗嗦了，直接上搭建步骤。 配置环境安装Node（必须）作用：用来生成静态页面的到Node.js官网下载相应平台的最新版本，一路安装即可。 安装Git（必须）作用：把本地的hexo内容提交到github上去.安装Xcode就自带有Git，我就不多说了。 申请GitHub（必须）作用：是用来做博客的远程创库、域名、服务器之类的，怎么与本地hexo建立连接等下讲。github账号我也不再啰嗦了,没有的话直接申请就行了，跟一般的注册账号差不多，SSH Keys，看你自己了，可以不配制，不配置的话以后每次对自己的博客有改动提交的时候就要手动输入账号密码，配置了就不需要了，怎么配置我的简书上小神猫的简书,是在MAC上配置的。 正式安装HEXO Node和Git都安装好后，可执行如下命令安装hexo： 1$ sudo npm install -g hexo 初始化 创建一个文件夹，如：Blog，cd到Blog里执行hexo init的。命令： 1$ hexo init 好啦，至此，全部安装工作已经完成！ 生成静态页面继续再Blog目录下执行如下命令，生成静态页面 1$ hexo generate （hexo g 也可以） 本地启动启动本地服务，进行文章预览调试，命令： 1$ hexo server 浏览器输入http://localhost:4000我不知道你们能不能，反正我不能，因为我还有环境没配置好 常见的HEXO配置错误：12345ERROR Plugin load failed: hexo-server原因： Besides, utilities are separated into a standalone module. hexo.util is not reachable anymore.解决方法，执行命令：$ sudo npm install hexo-server 12345678910执行命令hexo server，提示：Usage: hexo&lt;Command&gt; ....原因：我认为是没有生成本地服务解决方法，执行命令：$ npm install hexo-server --save提示：hexo-server@0.1.2 node_modules/hexo-server.... 表示成功了[参考](https://hexo.io/zh-cn/docs/server.html) 这个时候再执行：$ hexo-server 得到: INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop. 这个时候再点击http://0.0.0.0:4000，正常情况下应该是最原始的画面，但是我看到的是：白板和Cannot GET / 几个字原因： 由于2.6以后就更新了，我们需要手动配置些东西，我们需要输入下面三行命令： 1234567891011npm install hexo-renderer-ejs --savenpm install hexo-renderer-stylus --savenpm install hexo-renderer-marked --save这个时候再重新生成静态文件，命令：hexo generate （或hexo g）启动本地服务器：hexo server （或hexo s） 再点击网址http://0.0.0.0:4000 OK终于可以看到属于你自己的blog啦，虽然很简陋，但好歹有了一个属于自己的小窝了。参考链接，本地已经简单的设置好了，但是现在域名和服务器都是基于自己的电脑，接下来需要跟github进行关联。 配置Github建立Repository建立与你用户名对应的仓库，仓库名必须为【your_user_name.github.io】，固定写法然后建立关联，我的Blog在本地/Users/leopard/Blog，Blog是我之前建的东西也全在这里面，有： Blog ｜ ｜－－ _config.yml ｜－－ node_modules ｜－－ public ｜－－ source ｜－－ db.json ｜－－ package.json ｜－－ scaffolds ｜－－ themes 现在我们需要_config.yml文件，来建立关联，命令： 1vim _config.yml 翻到最下面，改成我这样子的，注意： : 后面要有空格 12345678deploy:type: gitrepository: https://github.com/xiaoshenmao/xiaoshenmao.github.io.gitbranch: master执行如下命令才能使用git部署npm install hexo-deployer-git --save 网上会有很多说法，有的type是github, 还有repository 最后面的后缀也不一样，是github.com.git，我也踩了很多坑，我现在的版本是hexo: 3.1.1，执行命令hexo -vsersion就出来了,貌似3.0后全部改成我上面这种格式了。忘了说了，我没用SSH Keys如果你用了SSH Keys的话直接在github里复制SSH的就行了，总共就两种协议，相信你懂的。然后，执行配置命令： 1hexo deploy 然后再浏览器中输入http://xiaoshenmao.github.io/就行了，我的 github 的账户叫 xiaoshenmao ,把这个改成你 github 的账户名就行了 部署步骤每次部署的步骤，可按以下三步来进行。 123hexo cleanhexo generatehexo deploy 一些常用命令： 1234567hexo new \"postName\" #新建文章hexo new page \"pageName\" #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）hexo deploy #将.deploy目录部署到GitHubhexo help #查看帮助hexo version #查看Hexo的版本 缩写： 1234hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 组合命令： 12hexo s -g #生成并本地预览hexo d -g #生成并上传 这里有大量的主题列表使用方法里面都有详细的介绍，我就不多说了。我这里有几款个人认为不错的主题，免去你们，一个一个的选了，欢迎吐槽我的审美，? Cover - A chic theme with facebook-like cover photo Oishi - A white theme based on Landscape plus and Writing. Sidebar - Another theme based on Light with a simple sidebar TKL - A responsive design theme for Hexo. 一个设计优雅的响应式主题 Tinnypp - A clean, simple theme based on Tinny Writing - A small and simple hexo theme based on Light Yilia - Responsive and simple style 优雅简洁响应式主题，我用得就是这个。 Pacman voidy - A theme with dynamic tagcloud and dynamic snow 一些基本路径 文章在 source/_posts，编辑器可以用 Sublime，支持 markdown 语法。如果想修改头像可以直接在主题的 _config.yml 文件里面修改，友情链接，之类的都在这里，修改名字在 public/index.html 里修改，开始打理你的博客吧，有什么问题或者建议，都可以提出来，我会继续完善的。 Markdown语法参考链接: 作业部落 Q&amp;A 问：如何让文章想只显示一部分和一个 阅读全文 的按钮？答：在文章中加一个 &lt;!--more--&gt; ， &lt;!--more--&gt; 后面的内容就不会显示出来了。 问：本地部署成功了，也能预览效果，但使用 username.github.io 访问，出现 404 .答：首先确认 hexo d 命令执行是否报错，如果没有报错，再查看一下你的 github 的 username.github.io 仓库，你的博客是否已经成功提交了，你的 github 邮箱也要通过验证才行。 转载请注明原地址，向宇辉的博客：http://xiaoshenmao.github.io 谢谢！","tags":[{"name":"hexo","slug":"hexo","permalink":"//xiaoshenmao.github.io/blog/tags/hexo/"},{"name":"blog","slug":"blog","permalink":"//xiaoshenmao.github.io/blog/tags/blog/"},{"name":"随笔","slug":"随笔","permalink":"//xiaoshenmao.github.io/blog/tags/随笔/"}]},{"title":"Wifi 定位原理及 iOS Wifi 列表获取","date":"2017-01-02T16:00:00.000Z","path":"2017/01/03/2017-01-03-iOS_Wifilist/","text":"对于大家来说，Wifi 应该是一个很熟悉的词了，我们每天都可能在使用 Wifi 热点。Wifi 除了能给我们提供热点之外同时还有定位的作用， 现在移动设备的对用户的隐私保护是越来越严格了，就如定位功能，必须要经过设备用户的授权才能使用 Location 给这台设备定位。这些严格的隐私政策对用户起到到保护作用，但对开发人员却是一种阻碍，在产品强需求的情况下用户是会授权的，如地图类应用，但是另外一些没有对定位强需求的产品，用户可能就不会给你授权了，这是我们可以考虑下 Wifi 定位了。 Wifi 定位原理 当我们使用手机扫面 Wifi 的时候，其实就可以定位到这台手机的位置信息了。每个 Wifi 路由开启后，都会不停的往四周发射信号，我们把 Wifi 路由想象成太阳以某种频度不停的往周围发射电磁波，电磁波会因距离的削弱，同时也会因为物体阻挡而削弱。例子就是我们在离 Wifi 路由器同样远的位置，有些地方信号强度高有些地方信号强度低。路由同时也叫 Wifi 热点（或者 Wifi AP：Access Point）。每一个 Wifi 路由器都会有一个 BSSID，很多人都管这个 BSSID 叫 MAC 地址（其实 BSSID 并不是 MAC 地址），BSSID 设定了一般就不会在变也不会重复，也就意味着是全球唯一的，这是路由制造的规则，既然有规则那么就会有不遵守规则的人，文章结尾会介绍不遵守规则的人是如何害人害己的。 刚才提到的 BSSID，在 Wifi 路由器的发射中是可以检测到的，同时 Wifi 路由信号还伴随着，SSID(路由器的名称：如XX的Wifi)、signalStrength（手机接收到Wifi的信号强度）及其它信息。看到这里你应该知道如何使用Wifi定位的了，条件：唯一不变的BSSID 和 手机到路由器的信号强度。思路：Wifi 信号是有范围的，我们假设这个范围就是10米为半径的一个圆(实际情况根据Wifi路由厂商和路由器周围环境而定)，我们去采集一些Wifi热点回来，某家水果店的 Wifi、某家餐馆的 Wifi 等等，我们自己去采集的我们肯定知道他们的具体位置，及刚才提到的 Wifi 中的信息：BSSID、SSID、signalStrength，再把他们存入数据库，采集的人可以很多：专业采集人员、出租车司机、快递员等等，他们经常穿梭于大街小巷，其实我们每个人都是Wifi数据库的采集人员，我们的手机厂商每天都在默默的采集着我们的位置信息，iPhone手机系统设置里就可以看到你今天去哪了，你的Wifi连接过哪些设备也是知道的。时间越久Wifi数据库信息越丰富，最终会发现每个BSSID会对应多个SSID和signalStrength，因为SSID是可以修改的，signalStrength是由于在这个Wifi热点的周围不同位置采集的，所以信号强度也不同。采集的信号强度越多，给BSSID也就是这个Wifi热点的定位就越精准。 现在如果我去一个陌生的地方，我打开手机扫描周围的 Wifi 刚好扫描到了一个或几个，我把这个 Wifi 信息（BSSID）传给服务器，服务器通过这个 BSSID 去数据库查找，就能直接匹配到对应的位置，返回给我。如果匹配不到则表示这里没人来采集过 Wifi 信息，或者是这个 Wifi 热点是最近布置的，采集人员还没来得及采集。服务器可以把这些未采集到的先分类后期统一规划。 Wifi 定位整体功能是需要服务端来配合的，也就表示必须要有网络环境才行。其实移动端(手机、Pad等)也可以独立完成，不过对技术和设备硬件要求会高很多，全球的 Wifi 热点是一个很庞大的数据量，需要经过高精度的无损压缩后放在内存很大的手机里才行，或许多年以后可以实现吧(即使技术上能实现了，对于产品和研发来说收益、风险、和工作量又是一场PK) iOS 申请获取 Wifi 列表权限 知道了原理有啥用呢，能实现么？好吧现在就遇到问题了，移动设备如今主要是 Andorid 和 iOS, Android 上可以直接扫描 Wifi 列表获取相关信息，自己去网上找找, 所以说会原理不一定会技术实现，我也就只能讲讲 iOS 的技术实现了。 iOS 上获取 Wifi 列表其实也有很大限制，在 iOS 9 以前是不能获取Wifi列表的，只能获取当前连接的 Wifi 信息，也就表示只有连接了 Wifi 才能定位，刚才文章说到的场景是，我在一个陌生的原理，拿出手机扫描 Wifi ，也就是我并没连接那里的 Wifi（我不知道密码我怎么连啊）。Apple 在 iOS 9 以后，提供了获取Wifi列表的API，但是获取Wifi列表是有门槛的，主要步骤有： 1、向 Apple 申请开发 Network Extension 权限 2、申请包含 Network Extension 的描述文件 3、配置 Info.plist 4、配置 entitlements 5、iOS 获取 Wifi 列表代码实现 6、获取Wifi列表回调 1、向 Apple 申请开发 Network Extension 权限 首先要先写封邮件给 networkextension@apple.com ，问苹果要开发 Network Extension 的权限。苹果收到邮件后会自动回复邮件，在 https://developer.apple.com/contact/network-extension/ 里面填写申请表格，内容包括： 12345678910111213Organization： Company / Product URL: What's your product's target market? What's your company's primary function? Describe your application and how it will use the Network Extension framework. What type of entitlement are you requesting? 。。。 申请后大概两周左右能收到 Aplle的 确认信，如： 1234567Hi, Thanks for your interest in the Network Extension APIs.We added a new template containing the Network Extension entitlements to your team.。。。。 2、申请包含 Network Extension 的描述文件 选择包含 Network Extension 的描述文件，后点击下载，下载完成双击描述文件。 3、配置 Info.plistXcode Info.plist 里 Required background modes 添加 一个 network-authentication(item) 4、配置 entitlementsDemo.entitlements（Demo是项目名称） 里添加 Key-Value: com.apple.developer.networking.HotspotHelper -&gt; YES 5、iOS 获取 Wifi 列表代码实现导入头文件 1#import &lt;NetworkExtension/NetworkExtension.h&gt; 代码实现 123456789101112- (void)getWifiList &#123; if (![[[UIDevice currentDevice] systemVersion] floatValue] &gt;= 9.0) &#123;return;&#125; dispatch_queue_t queue = dispatch_queue_create(\"com.leopardpan.HotspotHelper\", 0); [NEHotspotHelper registerWithOptions:nil queue:queue handler: ^(NEHotspotHelperCommand * cmd) &#123; if(cmd.commandType == kNEHotspotHelperCommandTypeFilterScanList) &#123; for (NEHotspotNetwork* network in cmd.networkList) &#123; NSLog(@\"network.SSID = %@\",network.SSID); &#125; &#125; &#125;];&#125; kNEHotspotHelperCommandTypeFilterScanList： 表示扫描到 Wifi 列表信息。 NEHotspotNetwork 里有如下信息： SSID：Wifi 名称 BSSID：站点的 MAC 地址 signalStrength： Wifi信号强度，该值在0.0-1.0之间 secure：网络是否安全 (不需要密码的 Wifi，该值为 false) autoJoined： 设备是否自动连接该 Wifi，目前测试自动连接以前连过的 Wifi 的也为 false 。 justJoined：网络是否刚刚加入 chosenHelper：HotspotHelper是否为网络的所选助手 官方文档连接 6、获取Wifi列表回调当你把上面的代码写完，并成功运行项目后，发现并没有Wifi列表的回调。因为你还没刷新Wifi列表，你需要： 打开手机系统设置 -&gt; WLAN -&gt; 系统 Wifi 列表加载出来时，上面代码部分才会回调，才能获取到 Wifi 列表。 这个时候你就能看到控制台源源不断的Log。 注意事项 1、获取Wifi列表功能由于是需要申请后台权限，所以能后台激活App(应用程序)，而且激活后App的进程能存活几个小时。 2、整个获取Wifi列表不需要App用户授权，也就是在App用户无感知下获取设备的Wifi列表信息，使用时请正当使用。 3、Wifi列表获取 NetworkExtension 是 iOS 9以后才出的，目前 iOS 9 已经覆盖很广了。 下面付一张来自 TalkingData 对iOS操作系统的统计报表，时间：2017-01-03 Q&amp;A在操作过程或者文章有问题的话欢迎在 原文 里提问或指正。 使用 Demo 我就不提供了，你如果没有申请 NetworkExtension 权限，提供了 Demo 你也无法使用。 参考资源：NEHotspotHelper NetworkExtension API iOS9.0 转载请注明：xiaoshenmao的博客 » Wifi 定位原理及 iOS Wifi 列表获取","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]},{"title":"iOS开发中的小问题记录","date":"2016-12-01T16:00:00.000Z","path":"2016/12/02/2016-12-02-iOS_Dev_Note/","text":"NSKeyedArchiver 自定义对象写文件如果存储的对象类名有变动，则需要设置clasName, 方法为：“setClassName:forClass:”使用 NSKeyedArchiver 进行数据持久化时, 系统会默认使用类名去建表，如果类名变了，那么使用新的类名肯定是从本地获取不到表的，代码执行崩溃。所以需要在 NSKeyedArchiver 或者 NSKeyedUnarchiver 时使用 “setClassName:forClass:” 指定类名。 断点配置：【Generate Debug Symbols】描述: 用来控制断点是否生效,关闭此功能，打包 .ipa 时，包体积会小很多。配置路径:【project/TARGETS/Build Settings/Apple LLVM7.1 - Code Genneration/Generate Debug Symbols】 捕获全局异常：【All Exception】描述: 用来捕捉整个项目在 Xcode 里执行时的异常。例如：try/catch 时 catch住的异常,【All Exception】可以直接定位到具体位置。配置路径: 异常捕捉(commod+7)/Xcode左下角点击+/Add Exception Breakpoint/完成(回车键) UI相关1、设置状态栏颜色： 123info.plist 添加 View controller-based status bar appearance - NO 代码里写 [[UIApplication sharedApplication] setStatusBarStyle:UIStatusBarStyleLightContent]; 再次运行后状态栏就会变成白色。 2、左滑返回手势失效了怎么办： 1234设置 navigationItem.leftBarButtonItem 之后，左滑返回手势就会失效。设置一下 UIGestureRecognizerDelegate 代理即可：self.navigationController.interactivePopGestureRecognizer.delegate = self; 3、让 TableView的 下拉 和 上拉 显示不一样的背景颜色： 1234给 TableView 上加一个 View，View 的 Frema：CGRectMake(0, -self.view.bounds.size.height, self.view.bounds.size.width, self.view.bounds.size.height + 2)，给变View的背景颜色就可以了。 转载请注明：xiaoshenmao的博客 » iOS开发中的小问题记录","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]},{"title":"使用 TensorFlow 实现神经网络","date":"2016-11-19T16:00:00.000Z","path":"2016/11/20/2016-11-20-neural_networks_using_TensorFlow/","text":"介绍 一直关注 数据科学 、 机器学习 的同学，一定会经常看到或听到关于 深度学习 和 神经网络 相关信息。如果你对 深度学习 感兴趣，但却还没有实际动手操作过，你可以从这里得到实践。 在本文中，我将介绍 TensorFlow , 帮你了解 神经网络 的实际作用，并使用 TensorFlow 来解决现实生活中的问题。 读这篇文章前，需要知道 神经网络 的基础知识和一些熟悉编程理念，文章中的代码是使用 Pyhton 编写的，所以还需要了解一些 Python 的基本语法，才能更有利对于文章的理解。 目录 什么时候应用神经网络？ 通常神经网络能解决的问题 了解图像数据和主流的库来解决问题 什么是 TensorFlow？ TensorFlow 一个 典型 的 “ 流 ” 在 TensorFlow 中实现 MLP TensorFlow 的限制 TensorFlow 与其他库 从这里去哪里？ 什么时候用神经网络？ 神经网络 已经在相当一段时间成为机器学习中的焦点。 对于 神经网络 和 深度学习 上这里有更详细的解释 点击阅读 。 其 “更深” 的功能在许多领域都有取得巨大的突破，如图像识别，语音和自然语言处理等。 主要的问题在于如何用好 神经网络 ？现在，每天都会有许多新发现，这个领域就像一个金矿，为了成为这个 “淘金热” 的一部分，必须记住几件事： 首先，神经网络 需要有明确和翔实的数据（主要是大数据）训练， 试着想象 神经网络 作为一个孩子，它一开始会观察它父母走路，然后它试图自己走，每一步就像学习执行一个特定的任务。 它可能会失败几次，但经过几次失败的尝试，它将会如何走路。所以需要为孩子提供更多的机会，如果不让它走，它可能永远不会学习如何走路。 一些人会利用 神经网络 解决复杂的问题，如图像处理， 神经网络 属于一类代表学习的算法，这些算法可以把复杂的问题分解为简单的形式，使他们成为可以理解的（或 “可表示”），就像吞咽食物之前的咀嚼，让我们更容易吸收和消化。这个分解的过程如果使用传统的算法来实现也可以，但是实现过程将会很困难。 选择适当类型的 神经网络 ，来解决问题， 每个问题的复杂情况都不一样，所以数据决定你解决问题的方式。 例如，如果问题是序列生成的问题，递归神经网络 更合适。如果它是图像相关的问题，想更好地解决可以采取 卷积神经网络。 最后最重要的就是 硬件 要求了，硬件是运行 神经网络 模型的关键。 神经网被 “发现” 很久以前，他们在近年来得到推崇的主要的原因就是计算资源更好，能更大发挥它的光芒，如果你想使用 神经网络 解决这些现实生活中的问题，那么你得准备购买一些高端的硬件了😆！ 通常神经网络解决的问题 神经网络是一种特殊类型的 机器学习（ML）算法。 因此，作为每个 ML 算法都遵循 数据预处理 、模型建立 和 模型评估 的工作流流程。为了简明起见，下面列出了如何处理 神经网络 问题的 TODO 列表。 检查它是否为 神经网络 ，把它看成一个传统的算法问题 做一个调查，哪个 神经网络 框架最适合解决这个问题 定义 神经网络 框架，通过它选择对应的 编程语言 和 库 将数据转换为正确的格式并分批分割 根据您的需要预处理数据 增强数据以增加大小并制作更好的训练模型 批次供给到 神经网络 训练和监测，培训和验证数据集的变化 测试你的模型，并保存以备将来使用 本文将专注于图像数据，我们从 TensorFlow 入手。 了解图像数据和主流的库来解决问题 图像大多排列为 3-D 阵列，具体指 高度、宽度 和 颜色通道。例如，如果你使用电脑截屏，它将首先转换成一个 3-D 数组，然后压缩它为 ‘.jpeg’ 或 ‘.png’ 文件格式。 虽然这些图像对于人类来说很容易理解，但计算机很难理解它们。 这种现象称为“语义空隙”。我们的大脑可以看看图像，并在几秒钟内读懂完整的图片。但计算机会将图像看作一个数字数组，问题来了，它想知道这是一张什么样的图像，我们应该怎么样把图像解释给机器它才能读懂？ 在早期，人们试图将图像分解为机器的 “可理解” 格式，如“模板”。例如，面部总是具有在每个人中有所保留的特定结构，例如眼睛，鼻子或我们的脸的形状。 但是这种方法将是有缺陷的，因为当要识别的对象的数量将增加到一定量级时，“模板” 将不成立。 2012年一个深层神经网络架构赢得了 ImageNet 的挑战，从自然场景中识别对象，它在即将到来的 ImageNet 挑战中继续统治其主权，从而证明了解决图像问题的有用性。人们通常使用哪些 库 / 语言 来解决图像识别问题？最近的一次调查中，最流行的深度学习库，支持的最友好的语言有 Python ，其次是 Lua ，对 Java 和 Matlab 支持的也有。最流行的库举几个例子： Caffe DeepLearning4j TensorFlow Theano Torch 现在，我们了解了图像的存储方式以及使用的常用库，让我们看看 TensorFlow 提供的功能。 什么是 TensorFlow ？让我们从官方定义开始. “TensorFlow 是一个开源软件库，用于使用数据流图进行数值计算。图中的节点表示数学运算，而图边表示在它们之间传递的多维数据阵列（也称为张量）。 灵活的架构允许您使用单一 API 将计算部署到桌面、服务器或移动设备中的一个或多个的 CPU 或 GPU 中。 如果感觉这听起来太高大上，不要担心。这里有我简单的定义，TensorFlow 看起来没什么，只是 numpy 有些难以理解。如果你以前使用过 numpy ，理解 TensorFlow 将是手到擒来！ numpy 和 TensorFlow 之间的主要区别是 TensorFlow 遵循惰性编程范例。 TensorFlow 的操作基本上都是对 session 的操作，它首先构建一个所有操作的图形，当我们调用 session 时 TensorFlow 就开始工作了。它通过将内部数据表示转换为张量（Tensor，也称为多维数组）来构建为可扩展的。 构建计算图可以被认为是 TensorFlow 的主要成分。想更多地了解一个计算图形的数学结构，可以阅读 这篇文章 。 通过上面的介绍，很容易将 TensorFlow 分类为神经网络库，但它不仅仅是如此。它被设计成一个强大的神经网络库， 但它有能力做更多的事情。可以构建它为其他机器学习算法，如 决策树 或 k-最近邻，你可以从字面上理解，你可以做一切你在 numpy 上能做的事情！我们暂且称它为 “全能的 numpy” 。 使用 TensorFlow 的优点是： 它有一个直观的结构 ，顾名思义它有 “张量流”，你可以轻松地可视每个图中的每一个部分。 轻松地在 cpu / gpu 上进行分布式计算 平台的灵活性 。可以随时随地运行模型，无论是在移动端、服务器还是 PC 上。 TensorFlow 的典型 “流” 每个库都有自己的“实现细节”，即一种写其遵循其编码范例的方式。 例如，当实现 scikit-learn 时，首先创建所需算法的对象，然后在训练和测试集上构建一个模型获得预测，如下所示： 1234567# define hyperparamters of ML algorithmclf = svm.SVC(gamma=0.001, C=100.)# train clf.fit(X, y)# test clf.predict(X_test) 正如我前面所说，TensorFlow 遵循一种懒惰的方法。 在 TensorFlow 中运行程序的通常工作流程如下： 建立一个计算图， 任何的数学运算可以使用 TensorFlow 支撑。 初始化变量， 编译预先定义的变量 创建 session， 这是神奇的开始的地方 ！ 在 session 中运行图， 编译图形被传递到 session ，它开始执行它。 关闭 session， 结束这次使用。 TensoFlow 中使用的术语很少 12placeholder：将数据输入图形的一种方法feed_dict：将数值传递到计算图的字典 让我们写一个小程序来添加两个数字！ 1234567891011121314151617181920# import tensorflowimport tensorflow as tf# build computational grapha = tf.placeholder(tf.int16)b = tf.placeholder(tf.int16)addition = tf.add(a, b)# initialize variablesinit = tf.initialize_all_variables()# create session and run the graphwith tf.Session() as sess: sess.run(init) print &quot;Addition: %i&quot; % sess.run(addition, feed_dict=&#123;a: 2, b: 3&#125;)# close sessionsess.close() 在 TensorFlow 中实现神经网络注意：我们可以使用不同的神经网络体系结构来解决这个问题，但是为了简单起见，我们在深入实施中讨论 前馈多层感知器。 让我们记住对神经网络的了解。 神经网络的典型实现如下： 定义要编译的神经网络体系结构 将数据传输到模型 整个运行中，数据首先被分成批次，以便它可以被摄取。首先对批次进行预处理，扩增，然后送入神经网络进行训练 然后，模型被逐步地训练 显示特定数量的时间步长的精度 训练后保存模型供将来使用 在新数据上测试模型并检查其运行方式 在这里，我们解决了我们深刻的学习实践中的问题 - [识别数字]，让再我们花一点时间看看问题陈述。 我们的问题是图像识别，以识别来自给定的 28×28 图像的数字。 我们有一个图像子集用于训练，其余的用于测试我们的模型。首先下载训练和测试文件。数据集包含数据集中所有图像的压缩文件， train.csv 和 test.csv 都有相应的训练和测试图像的名称。数据集中不提供任何其他功能，只是原始图像以 “.png” 格式提供。 如之前说的，我们将使用 TensorFlow 来创建一个神经网络模型。 所以首先在你的系统中安装 TensorFlow 。 请参考 官方的安装指南 进行安装，按您的系统规格。 我们将按照上述模板 让我们来 导入所有需要的模块 123456789%pylab inlineimport osimport numpy as npimport pandas as pdfrom scipy.misc import imreadfrom sklearn.metrics import accuracy_scoreimport tensorflow as tf 让我们来 设置一个种子值，这样我们就可以控制我们的模型随机性 1234# To stop potential randomnessseed = 128rng = np.random.RandomState(seed) 第一步是设置目录路径，以便保管！ 123456789root_dir = os.path.abspath('../..')data_dir = os.path.join(root_dir, 'data')sub_dir = os.path.join(root_dir, 'sub')# check for existenceos.path.exists(root_dir)os.path.exists(data_dir)os.path.exists(sub_dir) 现在让我们读取我们的数据集，这些是 .csv 格式，并有一个文件名以及相应的标签 12345train = pd.read_csv(os.path.join(data_dir，'Train'，'train.csv'))test = pd.read_csv(os.path.join（data_dir，'Test.csv'))sample_submission = pd.read_csv(os.path.join(data_dir，'Sample_Submission.csv'))train.head() 文件名 标签 0 0.png 4 1 1.png 9 2 2.png 1 3 3.png 7 4 4.png 3 让我们看看我们的数据是什么样子！我们读取我们的形象并显示出来。 123456789img_name = rng.choice(train.filename)filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)img = imread(filepath, flatten=True)pylab.imshow(img, cmap='gray')pylab.axis('off')pylab.show() 上面的图像表示为 numpy 数组，如下所示 为了方便数据操作，让我们 的存储作为 numpy 的阵列的所有图片 123456789101112131415161718temp = []for img_name in train.filename: image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name) img = imread(image_path, flatten=True) img = img.astype('float32') temp.append(img) train_x = np.stack(temp)temp = []for img_name in test.filename: image_path = os.path.join(data_dir, 'Train', 'Images', 'test', img_name) img = imread(image_path, flatten=True) img = img.astype('float32') temp.append(img) test_x = np.stack(temp) 由于这是典型的 ML 问题，为了测试我们的模型的正确功能，我们创建一个验证集，让我们以 70:30 的分割训练集 和 验证集 12345split_size = int(train_x.shape[0]*0.7)train_x, val_x = train_x[:split_size], train_x[split_size:]train_y, val_y = train.label.values[:split_size], train.label.values[split_size:] 我们定义一些辅助函数，我们稍后在我们的程序中使用 12345678910111213141516171819202122232425262728def dense_to_one_hot(labels_dense, num_classes=10): \"\"\"Convert class labels from scalars to one-hot vectors\"\"\" num_labels = labels_dense.shape[0] index_offset = np.arange(num_labels) * num_classes labels_one_hot = np.zeros((num_labels, num_classes)) labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1 return labels_one_hotdef preproc(unclean_batch_x): \"\"\"Convert values to range 0-1\"\"\" temp_batch = unclean_batch_x / unclean_batch_x.max() return temp_batchdef batch_creator(batch_size, dataset_length, dataset_name): \"\"\"Create batch with random samples and return appropriate format\"\"\" batch_mask = rng.choice(dataset_length, batch_size) batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, 784) batch_x = preproc(batch_x) if dataset_name == 'train': batch_y = eval(dataset_name).ix[batch_mask, 'label'].values batch_y = dense_to_one_hot(batch_y) return batch_x, batch_y 主要部分！ 让我们定义我们的神经网络架构。 我们定义一个神经网络具有 3 层，输入、隐藏 和 输出， 输入和输出中的神经元数目是固定的，因为输入是我们的 28×28 图像，并且输出是表示类的 10×1 向量。 我们在隐藏层中取 500 神经元。这个数字可以根据你的需要变化。我们把值 赋给 其余变量。 可以阅读 神经网络的基础知识的文章 ，以更深的了解它是如何工作。 12345678910111213141516171819202122232425262728293031### set all variables# number of neurons in each layerinput_num_units = 28*28hidden_num_units = 500output_num_units = 10# define placeholdersx = tf.placeholder(tf.float32, [None, input_num_units])y = tf.placeholder(tf.float32, [None, output_num_units])# set remaining variablesepochs = 5batch_size = 128learning_rate = 0.01### define weights and biases of the neural network (refer this article if you don't understand the terminologies)weights = &#123; 'hidden': tf.Variable(tf.random_normal([input_num_units, hidden_num_units], seed=seed)), 'output': tf.Variable(tf.random_normal([hidden_num_units, output_num_units], seed=seed))&#125;biases = &#123; 'hidden': tf.Variable(tf.random_normal([hidden_num_units], seed=seed)), 'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))&#125; 现在创建我们的神经网络计算图 12345hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])hidden_layer = tf.nn.relu(hidden_layer)output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output'] 此外，我们需要定义神经网络的成本 12cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(output_layer, y)) 设置优化器，即我们的反向传播算法。 这里我们使用 Adam ，这是梯度下降算法的高效变体。 有在 tensorflow 可用许多其它优化（参照 此处 ） 12optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) 定义我们的神经网络结构后，让我们来 初始化所有的变量 12init = tf.initialize_all_variables() 现在让我们创建一个 Session ，并在 Session 中运行我们的神经网络。我们还验证我们创建的验证集的模型准确性 1234567891011121314151617181920212223242526272829303132with tf.Session() as sess: # create initialized variables sess.run(init) ### for each epoch, do: ### for each batch, do: ### create pre-processed batch ### run optimizer by feeding batch ### find cost and reiterate to minimize for epoch in range(epochs): avg_cost = 0 total_batch = int(train.shape[0]/batch_size) for i in range(total_batch): batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'train') _, c = sess.run([optimizer, cost], feed_dict = &#123;x: batch_x, y: batch_y&#125;) avg_cost += c / total_batch print \"Epoch:\", (epoch+1), \"cost =\", \"&#123;:.5f&#125;\".format(avg_cost) print \"\\nTraining complete!\" # find predictions on val set pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1)) accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\")) print \"Validation Accuracy:\", accuracy.eval(&#123;x: val_x.reshape(-1, 784), y: dense_to_one_hot(val_y.values)&#125;) predict = tf.argmax(output_layer, 1) pred = predict.eval(&#123;x: test_x.reshape(-1, 784)&#125;) 这将是上面代码的输出 123456789Epoch: 1 cost = 8.93566Epoch: 2 cost = 1.82103Epoch: 3 cost = 0.98648Epoch: 4 cost = 0.57141Epoch: 5 cost = 0.44550Training complete!Validation Accuracy: 0.952823 验证我们自己的眼睛，让我们来 想象它的预言 12345678910111213img_name = rng.choice(test.filename)filepath = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)img = imread(filepath, flatten=True) test_index = int(img_name.split('.')[0]) - 49000print \"Prediction is: \", pred[test_index]pylab.imshow(img, cmap='gray')pylab.axis('off')pylab.show() 12Prediction is: 8 我们看到的模型性能是相当不错！ 现在让我们 创建一个提交 123456sample_submission.filename = test.filename sample_submission.label = predsample_submission.to_csv(os.path.join(sub_dir, 'sub01.csv'), index=False) 终于完成了！ 我们刚刚创建了自己的训练神经网络！ TensorFlow 的限制 尽管 TensorFlow 是强大的，它仍然是一个低水平库，例如，它可以被认为是机器级语言，但对于大多数功能，您需要自己去模块化和高级接口，如 keras 它仍然在继续开发和维护，这是多么👍啊！ 它取决于你的硬件规格，配置越高越好 不是所有变成语言能使用它的 API 。 TensorFlow 中仍然有很多库需要手动导入，比如 OpenCL 支持。 上面提到的大多数是在 TensorFlow 开发人员的愿景，他们已经制定了一个路线图，计划库未来应该如何开发。 TensorFlow 与其他库 TensorFlow 建立在类似的原理，如使用数学计算图表的 Theano 和 Torch，但是随着分布式计算的额外支持，TensorFlow 更好地解决复杂的问题。 此外，TensorFlow 模型的部署已经被支持，这使得它更容易用于工业目的，打开一些商业的三方库，如 Deeplearning4j ，H2O 和 Turi。 TensorFlow 有用于 Python，C ++ 和 Matlab 的 API 。 最近还出现了对 Ruby 和 R 等其他语言的支持。因此，TensorFlow 试图获得通用语言支持。 从这里去哪里？ 以上你看到了如何用 TensorFlow 构建一个简单的神经网络，这段代码是为了让人们了解如何开始实现 TensorFlow。 要解决更复杂的现实生活中的问题，你必须在这篇文章的基础上在调整一些代码才行。 许多上述功能可以被抽象为给出无缝的端到端工作流，如果你使用 scikit-learn ，你可能知道一个高级库如何抽象“底层”实现，给终端用户一个更容易的界面。尽管 TensorFlow 已经提取了大多数实现，但是也有更高级的库，如 TF-slim 和 TFlearn。 参考资源 TensorFlow 官方库 Rajat Monga（TensorFlow技术负责人） “TensorFlow为大家” 的视频 一个专用资源的策划列表 关于原文感谢原文作者 Faizan Shaikh 的分享，这篇文章是在 An Introduction to Implementing Neural Networks using TensorFlow 的基础上做的翻译和局部调整，如果发现翻译中有不对或者歧义的的地方欢迎在下面评论里提问，我会加以修正 。 转载请注明：xiaoshenmao的博客 » 使用 TensorFlow 实现神经网络","tags":[{"name":"机器学习","slug":"机器学习","permalink":"//xiaoshenmao.github.io/blog/tags/机器学习/"}]},{"title":"Markdown工具集","date":"2016-11-19T16:00:00.000Z","path":"2016/11/20/2016-11-20-markdownTool/","text":"什么是 Markdown Markdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：如您正在阅读的这篇文章。它使用简单的符号标记不同的标题，分割不同的段落，粗体 或者 斜体 某些文字. 很多产品的文档也是用markdown编写的，并且以“README.MD”的文件名保存在软件的目录下面。 一些基本语法标题H1 :# Header 1H2 :## Header 2H3 :### Header 3H4 :#### Header 4H5 :##### Header 5H6 :###### Header 6链接 :Title加粗 :Bold斜体字 :Italics删除线 :text段落 : 段落之间空一行换行符 : 一行结束时输入两个空格列表 : 添加星号成为一个新的列表项。引用 :&gt; 引用内容内嵌代码 : alert(&#39;Hello World&#39;);画水平线 (HR) :——– css 的大部分语法同样可以在 markdown 上使用，但不同的渲染器渲染出来的 markdown 内容样式也不一样，下面这些链接里面有 markdown 基本语法，你也可以在下面几个平台上尝试着写一些。 一些好用的 Markdown 编辑器 MaHua 在线 Markdown 编辑器 ,无须测试。 Markdown Plus 一款 Markdown 编辑器，可以支持添加任务列表、emoji、流程图等。 Cmd Markdown 作业部落在线 Markdown 编辑器推出桌面版客户端啦，全平台支援。 Macdown Github 上开源的 Mac 平台上的 Markdown 编辑器 GitBook Editor 一款团队在线编辑文档工具。可以轻松书写笔记，支持团队协同编辑。同时支持 Markdown 语法，还保持了印象笔记的风格并可在线预览。 Outlinely 界面简洁大方的大纲类 Mac 软件，使用起来很简单，而且支持输出 Markdown 格式。 Classeur 实用简洁的 Markdown 写作工具，快速上手。 DeerResume 程序员专用 MarkDown 简历制作在线工具。 转载请注明：xiaoshenmao的博客 » Markdown工具集","tags":[{"name":"工具","slug":"工具","permalink":"//xiaoshenmao.github.io/blog/tags/工具/"}]},{"title":"Mac知识整合","date":"2016-11-15T16:00:00.000Z","path":"2016/11/16/2016-11-16-macTips/","text":".DS_Store 文件是什么？.DS_Store 是 Mac OS 保存文件夹的自定义属性的隐藏文件，如文件的图标位置或背景色，相当于 Windows 的 desktop.ini。 1，禁止.DS_store 生成：打开 “终端” ，复制黏贴下面的命令，回车执行，重启Mac即可生效。 1defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUE 2，恢复.DS_store生成： 1defaults delete com.apple.desktopservices DSDontWriteNetworkStores 显示隐藏文件在终端执行命令，显示隐藏文件 1defaults write com.apple.finder AppleShowAllFiles -bool true 恢复隐藏 1defaults write com.apple.finder AppleShowAllFiles -bool false 执行命令后需要重新打开能看到效果。 切换 Pyhton 环境我本地之前 Python 环境是 2.7.10 ，然后学习 Tensorflow 的时候，安装了 Python 3.5.2 ，把系统默认 Pyton 环境也设置成了 3.5.2 版本，今天运行以前写的 python 脚本发现运行不了了，因为python 2.7 和 3.5 的 语法有挺多改动，现在我需要把系统的 python 环境回退到 2.7。 可以直接修改 ~/.bash_profile 文件。 1、修改 vim ~/.bash_profile 1修改方式有很多种，使用 vim ，或者 cd ~/ 然后 open . 打开文件夹，找到 .bash_profile 文件，双击打开。 2、在.bash_profile 文件里添加下面参数 1alias python=\"/System/Library/Frameworks/Python.framework/Versions/2.7/bin/python2.7\" 3、使用命令 source ~/.bash_profile 或者重启 终端 就 OK 了 。 现在你再在终端输入 python 就会发现，显示的信息为 2.7 了 1234Python 2.7.10 (default, Oct 23 2015, 19:19:21) [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)] on darwinType \"help\", \"copyright\", \"credits\" or \"license\" for more information. 生成SSHKey过程1234567891.查看是否已经有了ssh密钥：`cd ~/.ssh` ，如果没有密钥则不会有此文件夹，有则备份删除。 2.生存密钥：ssh-keygen -t rsa -C “test@gmail.com”。 按3个回车，密码为空。 Your identification has been saved in /home/tekkub/.ssh/id_rsa.Your public key has been saved in /home/tekkub/.ssh/id_rsa.pub.The key fingerprint is:……………… 最后得到了两个文件：id_rsa和id_rsa.pub 使用版本控制器 SVN (versions) 添加.a库Xcode 自带的 svn 和 Versions 以及一些其它工具都不能上传”.a”文件 下面是在 Mac 上如何把 .a 添加到 SVN 里面的 1、打开终端，输入cd，空格，然后将需要上传的 .a 文件所在的文件夹（不是.a文件） 拖拽到终端（此办法无需输入繁琐的路径，快捷方便） 回车 2、之后再输入如下命令：svn add libGoogleAnalytics.a ，回车 之后会出现：A (bin) libGoogleAnalytics.a 表示添加成功，打开 Versions 就可以看到，刚才添加的 .a 文件，此时就可以手动上传了。 另外，请注意路径的正确性。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]},{"title":"TensorFlow 在 iOS 平台上的使用(一)","date":"2016-11-02T16:00:00.000Z","path":"2016/11/03/2016-11-03-TensorFlowOniOSUse1/","text":"距离上次使用 TensorFlow 在iOS平台上做的小 Demo，已经过了四个月了，今天忽然想再看看,发现 Demo 已经不见了，我只能从头在编一次，这次发现编译 iOS 库，简单多了。 tensorflow 下载地址，tensorflow 最近提交的时间：2016-11-03，commit：7b7c02de56e013482b5fe5ab05e576dc98fe5742 。 下载完成后打开文件，找到目录 tensorflow-master/tensorflow/contrib/ios_examples 你会发现目录下有三个项目和一个 README.md 。 1benchmark 、 camera 、 simple 、README.md 如果你发现项目无法运行，请看这里 对于任何项目我们首先打开的应该是 README.md ，里面一般情况都会有介绍如何使用这个项目，tensorflow 也不会例外。README 开头就说了，这个目录里有如何在 iOS 平台上使用 tensorflow 的例子，但是需要注意几点： 你的 Xcode 版本必须是 7.3 或更高版本，并且有安装 command-line 工具 。 项目(Examples) 里必须包含一个静态库：libtensorflow-core.a 。 下载 Inception v1，解压后将 label 和 graph 放在 simple 和 camera 的项目中。 camera 项目的使用 camera 项目在 tensorflow-master/tensorflow/contrib/ios_examples 目录下，如果你是直接打开 camera 项目，编译你会发现报错缺少 imagenet_comp_graph_label_strings.txt 和 tensorflow_inception_graph.pb 两个文件，这两个文件上面已经说到了下载 Inception v1 解压得到。现在还差 静态库：libtensorflow-core.a ，这个需要我们自己编译。 编译静态库：libtensorflow-core.a进入目录：tensorflow-master/tensorflow/contrib/makefile，你可以看到一大堆 .sh 结尾的文件，找到 build_all_ios.sh ，Mac 上可以直接在 termina（终端）上运行命令编译 1$ sh build_all_ios.sh 这个编译的过程是很漫长的，一般在一个小时左右。也有可能你在编译的过程中会遇到问题，这次我只遇到一个问题： 12345configure.ac:30: error: required file 'build-aux/ltmain.sh' not foundconfigure.ac:24: installing 'build-aux/missing'Makefile.am: installing 'build-aux/depcomp'parallel-tests: installing 'build-aux/test-driver'autoreconf: automake failed with exit status: 1 解决方法是：先卸载 libtool 在重新安装，brew uninstall libtool &amp;&amp; brew install libtool 如果你还遇到了其它问题，可以看看我之前的一片文章 iOS开发迎来机器学习的春天—TensorFlow ，或者是直接去 tensorflow 的 Issues 里面找。 一个小时后。。。 如果编译没出问题，你可以在目录 tensorflow-master/tensorflow/contrib/makefile／gen/lib 下找到一个静态库：libtensorflow-core.a ，把这个静态库拷贝到 camera 项目中，然后编译运行。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"机器学习","slug":"机器学习","permalink":"//xiaoshenmao.github.io/blog/tags/机器学习/"}]},{"title":"Xcode 8 使用笔记","date":"2016-10-24T16:00:00.000Z","path":"2016/10/25/2016-10-25-Xcode8/","text":"最近使用 Xcode8遇到了一些问题，想记下来，发现简书上有位同学写了一篇很详细的教程 原文链接，比较懒惰的我就在他的基础上加了些我自己的一些笔记。 Interface Builder随着 14 年的 iPhone6 和 6P 出来之后，iPhone 的屏幕尺寸也越来越多，屏幕适配是一个需要解决的问题，以后不一定苹果又出什么尺寸的 iPhone 呢。 在 iPhone6 和 6P 发布的同一年，苹果推出的 Xcode6 中在原有的 Auto layout的基础上，添加了Size Classes新特性，通过这个新特性可以使用一个XIB或者SB文件，适配不同的屏幕以及iPhone和iPad两种设备。 在 Xcode8 中，苹果推出了更加强大的可视化编辑工具预览功能，可以在不运行App的情况下，预览当前XIB或SB在不同屏幕尺寸下的显示。(这个功能我记得之前Xcode就有，只是隐藏的比较深，苹果现在给拿到外面了) 选择一个XIB文件进去，点击下面红框的位置，会出现从3.5寸-5.5寸一系列屏幕尺寸的选项。直接点击不同屏幕尺寸，以及横竖屏选项，切换不同的屏幕显示。在iPad上还可以选择是否分屏，功能非常强大。 在右边有一个 Vary for Traits 选项，点击这个选项就可以同时显示所有可选的屏幕样式，功能和上面图片都一样，只是显示上看起来比较多。 还有一点，新创建的 XIB 控件尺寸，不再是之前 600*600 的方块了，而是默认是6s的长方形 XIB 文件，看起来舒服多了。 Target中General 的变化在 Xcode8 之前，都需要自己设置证书和描述文件。如果设置出现错误的情况下，还可以通过点击 Fix issue 来修复这个错误。但这有个问题就在于，Fix issue 选项并不是那么好用，有的时候设置是正确的这里也提示需要 Fix issue。 可能苹果也意识到这个问题的存在，在Xcode8中可以通过Automatically manage signing选项，让苹果为我们管理证书和配置文件，设置也都是由苹果来完成的。在Xcode8中新建项目，这个选项默认是被勾选的。 从上面图中可以看到，苹果帮我们自动管理了证书和配置文件。而且在之前的项目中，如果想要设置安装后显示在手机上的App名字，还需要自己到Info.plist文件中，修改Display Name字段，而现在直接在General中就可以做修改，这个修改和Info.plist是同步的。 但是，如果我想自己管理证书和描述文件呢？只需要去掉Automatically manage signing选项。 如果自己到Build Settings中手动设置证书和描述文件，可以发现Provisioning Profile选项已经被标明为Deprecated，也就是苹果并不推荐手动设置。 Xcode 插件升级 Xcode8 之后会发现，在 Xcode8 中所有第三方插件都失效了，并且连之前菜单栏的插件选项也不存在了。在之前很多 iOS 开发者，都是通过 Alcatraz 来管理插件的，现在 Alcatraz 也是不可用的。但是X code8 自身也对编译器进行了升级，将一些比较好的插件功能加入到 Xcode 中，例如单行高亮显示等。 在 Xcode8 中支持了开发插件工程，并且为我们提供了一个插件模板，开发的插件可以上传到App Store 下载。苹果这么做有一个原因在于，之前 Xcode和插件是运行在同一个进程的，所以插件的崩溃也会导致Xcode崩溃。苹果现在将插件作为一个单独的应用程序，分开进程运行，不会对Xcode带来其他影响。 Runtime Issues在开发过程中，因为语法或明显的代码错误(例如Retain Cycle)，编译器可以发现并报黄色或红色警告。但是一些因为代码逻辑导致的错误，编译器并没有办法找到。例如下面的这句代码，因为代码逻辑的问题导致两个数组相互引用，都不能释放。 这时候可以通过 Xcode8 提供的 Runtime Issues 新特性，查找到运行过程中出现的问题，并通过 Graph 的方式将问题可视化的展现给开发者。 Debug Memory Graph在Xcode6中出现了Debug View Hierarchy新特性，可以通过其调试当前App的视图层级，查找UI相关的bug非常方便。在Xcode8中苹果为开发者提供了Debug Memory Graph特性，通过这个新特性，可以直接选择一个对象，查看与其相关的内存关系。 Debug Memory Graph 和 Runtime Issues 可以配合使用，通过 Debug Memory Graph 分析内存关系完成后，点击 Runtime Issues 可以看到已经发现的内存问题。 Swift 3Xcode8 带来了新版本的 Swift3，新版本的Swift变化较大，如果旧版的Swift项目在Xcode8上编译可能会失败。对此，苹果为开发者提供了Swift迁移工具，听说不太好用(我没用过这个工具)。 如果不想立刻就迁移到Swift3，可以在Builder Settings中进行设置，选择Use Legacy Swift Language Version设置为YES，就可以继续使用旧版本的Swift2.3。 其他更新Xcode 新版字体，SF Mono Regular 字体。更新 Xcode 之后我比较喜欢这种字体，看起来代码非常工整。被编辑的行高亮显示。之前Xcode有个插件就是这个功能，Xcode8把高亮功能集成进来了，使用起来很方便。最新版的API文档，展示样式发生了很大的改变。更方便的生成文档(就是喵神写的VVDocumenter)，在Xcode8中可以将光标放在方法上面，通过option + command + /快捷键生成文档注释。 Xcode8适配,XIB和Storeboard适配在 Xcode8 之前，创建一个 XIB 或 SB 文件，都是一个 600*600 的方块 XIB 文件。在 Xcode8 之后，创建的 XIB 文件默认是6s尺寸的大小。 但是 Xcode8 打开之前旧项目的 XIB或SB 文件时，会弹出下面的弹框， 这时候一般直接选择Choose Device即可。 但是这样有个问题，如果Xcode8打开过这个XIB文件，并选择Choose Device之后。其他的Xcode8以下版本的编译器，将无法再打开这个文件，会报以下错误： The document “ViewController.xib” requires Xcode 8.0 or later. This version does not support documents saved in the Xcode 8 format. Open this document with Xcode 8.0 or later.有两种方法解决这个问题： 你同事也升级Xcode8，比较推荐这种方式，应该迎接改变。右击XIB或SB文件 -&gt; Open as -&gt; Source Code，删除xml文件中下面一行字段。 编译错误升级Xcode之后，Xcode8对之前的一些修饰符和语句不兼容，会导致一些编译错误。这种错误导致的原因很多，这里大致列几条，各位还是根据自身遇到的情况做修改吧。 之前一些泛型相关的修饰符，nullable之类的有的会报错。CAAnimation及其子类，设置代理属性后，必须在@interface()遵守代理，否则报错，等等。 权限适配这应该算iOS10系统适配的范畴，最近这两个都在弄，所以就直接和Xcode8适配一起写出来了。 在iOS10之后需要在Info.plist中，添加新的字段获取权限，否则在iOS10上运行会导致崩溃。下面是一些常用的字段，如果有缺少的麻烦各位评论区补充一下。 Key 权限Privacy - Camera Usage Description 相机Privacy - Microphone Usage Description 麦克风Privacy - Photo Library Usage Description 相册Privacy - Contacts Usage Description 通讯录Privacy - Bluetooth Peripheral Usage Description 蓝牙Privacy - Location When In Use Usage Description 定位Privacy - Location Always Usage Description 后台定位Privacy - Calendars Usage Description 日历 参考资料：developer.apple 推送通知苹果的推送在之前iOS8和iOS9的时候就发生过大的更新，推送功能越来越强大。在iOS10之后苹果推出了UserNotifications框架，可以通过这个框架更好的控制推送通知，可以更新、修改锁屏页面的推送消息，可以添加图片等功能。 但是在用Xcode8打包后，并且不对代码进行修改的情况下，会发现打包后苹果发来了一封邮件。这封邮件大概意思是如果需要使用推送通知，需要对代码做修改，否则将不能使用推送通知。 这是因为在Xcode8之后，如果需要使用Push Notifications的功能，需要勾选Capabilities -&gt; Push Notifications为YES，否则进行远程推送就会有问题，并且会收到苹果发来的这封邮件。 删除系统log升级Xcode8之后，在调试和运行过程中，发现控制台打印了很多不认识的log，这些log是系统打印的，和开发者没关系。但是这么多log看着比较乱，怎么屏蔽掉呢？ subsystem: com.apple.UIKit, category: HIDEventFiltered, enable_level: 0, persist_level: 0, default_ttl: 0, info_ttl: 0, debug_ttl: 0, generate_symptoms: 0, enable_oversize: 1, privacy_setting: 2, enable_private_data: 0在Target -&gt; Edit Scheme -&gt; Run -&gt; Arguments中，添加OS_ACTIVITY_MODE字段，并设置为Disable即可。 顺便提一下，这两天在设置log选项的时候，发现可以通过在Arguments中设置参数，打印出App加载的时长，包括整体加载时长，动态库加载时长等。 在Environment Variables中添加DYLD_PRINT_STATISTICS字段，并设置为YES，在控制台就会打印加载时长。 awakeFromNib报警告老项目在Xcode8中，有些重写awakeFromNib方法的地方，会报下面的错误。这是因为没有调用super的方法导致的，还好我平时都是调用super的，我代码目前还没出问题。 1Method possibly missing a [super awakeFromNib] call","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]},{"title":"iOS设备左下角出现Appicon","date":"2016-09-22T16:00:00.000Z","path":"2016/09/23/2016-09-23-iOSLowerLeftAppicon/","text":"最近发现我设备锁屏后，按Home屏幕变亮的时候，左下角出现一个灰色的Appicon （应用图标），关于这个应用图标的出现做了一些调研，下面是应用图标出现的几种情况。 图一 iOS 系统自带的 App icon , 图二 第三方 App icon , 图三 通过 iBeacon 信号激活的 demo icon 结论：有三种情况导致设备的左下角出现灰色的 App icon1、AppStore根据地点对App 推荐 简介 iOS 8会基于你的位置在锁屏界面上展示一个app快捷打开方式。比如你正在星巴克附近，那iOS 8会在锁屏界面上展示星巴克应用的icon，方便你快速打开。一些用户也表示会在锁屏界面收到app推荐，比如你在Costco和Apple Store附近，即便你之前没有安装过这些应用。 2、App实现了handoff功能 handoff简介： OS X 10.10 Yosemite 新增了一个酷炫的功能 “Hand Off”，打开这个功能之后，用户可以在 Mac 上对 iPad 和 iPhone 进行操作，比如能够编写 iPhone 上未完成的邮件，并且可以在Mac上打开 iPhone 的热点等等， Mac 的 Hand Off 功能只能识别 Mac 周围的 iPhone 手机。 handoff有几个要求： 1 两台设备都要登录同一个 iCloud 账号。 2 两台设备上的app有相同的 TeamID 。 3 锁屏（或dock）设备上的app支持的 NSUserActivityTypes 包含活动设备上的app当前的UserActivityType。 3、App内有iBeacon信号接收功能，App被iBeacon信号唤醒 iBeacon简介： 是苹果公司2013年9月发布的移动设备用OS（iOS7）上配备的新功能。工作原理类似之前的蓝牙技术，由 iBeacon 发射信号，iOS设备定位接受，反馈信号。根据这项简单的定位技术可以做出许多的相应技术应用,如：室内定位 、商品推荐 、微信摇一摇 等。 App icon出现的原因： iBeacon 具备后台定位的能力，只要用户把蓝牙(4.0或以后)开启 和 允许 App 访问位置信息。在有被 App 检测的 iBeacon 出现时，如果设备是锁屏状态，设备的左下角就会出现该 App 的 icon 。 参考链接:Make app appear as iOS 8 Suggested App at lockscreenCan I get my iOS app to appear on the lower left corner of the lock screen?为什么 iOS 8 锁屏界面的左下角经常会出现某个应用的小图标？关于 IOS8 锁屏左下方出现的 APP ICON 转载请注明：xiaoshenmao的微博 » 点击阅读原文","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]},{"title":"Python自动化测试iOS项目","date":"2016-08-03T16:00:00.000Z","path":"2016/08/04/2016-08-04-PythonTestAutomationiOS/","text":"作为一个开发人员，为了保证自己的代码的健壮，写单元测试是必不可少的环节，然而最痛快的是每天去手动跑一遍所有的case。那么什么能帮我们解决这些繁琐的操作呢，大家应该会想到自动化测试脚本了，是的，我们可以借助脚本来完成全自动化测试，下面是我列的每天脚本自动执行流程： 1、pull git仓库里面的最新代码到本地。 2、然后打包成App。 3、安装到模拟器上。 4、运行App，执行单元测试，生成测试数据并保存到本地。 5、脚本读取测试数据，邮件发送给相关人员。 当这些全自动化后，可以大大减少开发人员的维护成本，即使每次项目里面有新增模块后，增加测试case就行了，下面会介绍自动测试这5步具体怎么去执行，整个脚本是使用Python写的，代码很少功能也很简单，但这已经可以帮我们完成基本的自动化测试了，这就是脚本的强大之处，选择Pyhton纯属个人喜好，最近也在学习Python，当然了最终使用什么语言看你自己。 python执行shell命令完成测试首先确认本机上安装了git 和 python 。脚本判断本地是否存在项目，不存在则使用命令 git clone ... ，存在则使用命令 git pull ... 。这些在Linux的命令都可以使用脚本来完成的，python的 os.popen() 方法 就是可以在Linux上执行shell命令。例如： 把下面这段代码添加到一个 test.py 的文件里，然后在终端上执行 python test.py 命令你就会看到，你的当前目录下正在下载我的博客了。 import os os.popen(&apos;git clone https://github.com/leopardpan/leopardpan.github.io.git&apos;) git pull 。。。 更新代码也是一样的。 接下来的打包、安装、运行都是使用python执行shell命令 把iOS项目打包成App，下面的 Demo 是项目的名字 os.popen(‘xcodebuild -project Demo.xcodeproj -target Demo -configuration Debug -sdk iphonesimulator’) 这行脚本运行完成后，你就会发现同会生成一个 build 的文件夹。Debug参数表示现在是Debug模式，如果Xcode里面改成Release了，这里需要改成Release。xcodebuild 命令是 Xcode Command Line Tools 的一部分。通过调用这个命令，可以完成 iOS 工程的编译，打包和签名过程。可以使用 xcodebuild –help 来看看具体有哪些功能。 打开iOS模拟器，这里运行的是iPhone 6 Plus 你也可以换成其它型号的模拟器 os.popen(‘xcrun instruments -w “iPhone 6 Plus”‘) 把刚才打包生成的App安装到模拟器上在安装之前要先卸载App,不然你运行的永远是最初安装的那个，后来安装的不会覆盖之前的，卸载App os.popen(‘xcrun simctl uninstall booted com.test.Demo’) booted 后面接的是 Bundle Identifier，我的是 com.test.Demo，然后再安装App os.popen(‘xcrun simctl install booted build/Debug-iphonesimulator/Demo.app ‘) booted 后面接的是.app的路径，我打包的时候的是Debug，所以这个的文件夹名称是Debug-iphonesimulator。 在模拟器里运行App os.popen(‘xcrun simctl launch booted com.test.Demo’) booted 后面接的是 Bundle Identifier，我的是 com.test.Demo。 到目前为止，你就会发现你的项目已经运行起来了，你可以在项目是Debug模式下一启动就执行单元测试，然后把对应的测试数据保存到本地为data.json。然后在使用python脚本读取测试文件的数据，最终使用邮件发送给相关人员，pyhton读取数据很简单，一行代码就行 data = open(‘data.json’).read() data里面就是json字符串，为了脚本操作简单，我在存储的时候直接把json格式的转成了字符串类型。 python发送邮件我使用的是SMTP进行邮件发送的，SMTP是发送邮件的协议，Python内置对SMTP的支持，可以发送纯文本邮件、HTML邮件以及带附件的邮件。 Python对SMTP支持有smtplib和email两个模块，email负责构造邮件，smtplib负责发送邮件，具体代码如下： from email import encoders from email.header import Header from email.mime.text import MIMEText from email.utils import parseaddr, formataddr import smtplib def format_addr(self,s): name, addr = parseaddr(s) return formataddr(( \\ Header(name, &apos;utf-8&apos;).encode(), \\ addr.encode(&apos;utf-8&apos;) if isinstance(addr, unicode) else addr)) def send_mail(self, mail, message, title): from_addr = &apos;leopardpan@163.com&apos; password = &apos;&apos; to_addr = mail smtp_server = &apos;smtp.163.com&apos; msg = MIMEText(message, &apos;plain&apos;, &apos;utf-8&apos;) msg[&apos;From&apos;] = self.format_addr(u&apos;自动化测试邮件 &lt;%s&gt;&apos; % from_addr) msg[&apos;To&apos;] = self.format_addr(u&apos;管理员 &lt;%s&gt;&apos; % to_addr) msg[&apos;Subject&apos;] = Header(title, &apos;utf-8&apos;).encode() server = smtplib.SMTP(smtp_server, 25) server.set_debuglevel(1) server.login(from_addr, password) server.sendmail(from_addr, [to_addr], msg.as_string()) server.quit() send_mail(&apos;leopardpan@icloud.com&apos;,&apos;正文&apos;,&apos;标题&apos;) from_addr是发送方的邮箱地址，password是开通SMTP时输入的密码smtp_server是smtp的服务，如果你的from_addr是gamil.com，那么就要写成smtp_server = ‘smtp.gmail.com’ 了。 方法 send_mail(self, mail, message, title): 有四个参数，第一个不用传，第二个参数是收信人的邮箱，第三个是邮件的正文，第四个是邮件的标题，方法调用格式： send_mail(&#39;leopardpan@icloud.com&#39;,&#39;正文&#39;,&#39;标题&#39;) 注意：发送方的邮箱必须要开通SMTP功能才行，否则会报错 SMTPSenderRefused: (550, ‘User has no permission’, ‘leopardpan@163.com’) 163的SMTP开通，需要你登录网易邮箱，然后点击顶部的设置就会出现POP3/SMTP/IMAP，点击之后，勾选选择开启，这个时候需要你输入密码，记住这个密码就是上面代码中的password，如果你都完成的话，你把上面的代码拷贝出现，把邮箱修改成你自己的，使用 pyhton 运行一下吧。 上面的几个流程结合起来就可以实现一个简单的自动化测试了，如果你有什么建议和意见欢迎讨论。 参考链接：SMTP发送邮件 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"python","slug":"python","permalink":"//xiaoshenmao.github.io/blog/tags/python/"}]},{"title":"老司机带你剖析无码统计","date":"2016-07-14T16:00:00.000Z","path":"2016/07/15/2016-07-15-Codeless/","text":"无需开发介入，也可以统计移动App上按钮的点击次数，简称 无码统计 ，只要是跟App开发相关的同学，相信都对埋点统计有些了解，特别是针对开发人员来说，做代码埋点统计基本上是看不到直接收益也是开发人员最不愿做的一件事，这篇文章讲的就是如何让开发人员摆脱代码埋点的痛苦。 文章主要分为：使用场景、实现原理、适用范围、使用详情四个模块，不管你是产品，还是开发人员又或者是运营人员都适合读这篇文章。 在App开发过程中我们应该都有过类似的需求：想统计某些按钮的点击次数。例如，我们开发了一个注册模块，注册流程有些复杂，整个注册功能开发完成后，我们想知道到底有没有用户使用注册功能，而又有多少用户使用？ 有什么方式能知道呢？ 后台看注册系统? 有些麻烦，需要后台去数据库里查看，还要做成数据可视化的才方便看。 查看注册按钮的点击情况? 这是最直观的。 主看看两块就行，注册按钮的点击次数 和 提交注册按钮的点击次数，如果发现注册按钮被点击多次（如1W次），而提交注册的点击次数却只有几次，这就可以反映出，很多用户看到的我们的注册流程太复杂，然后选择放弃注册了。同样的道理，我们通过同样的方式可以验证我们其它的功能模块是否有用户经常使用，从而来重新规划我们的设计需求。 一整个功能模块的完成涉及到 产品、UI设计、开发、测试 等几个部分，资源和人力的消耗还是挺大的，所以我们在开发过程是否继续维护这些功能模块，还是开发新功能是要经过慎重衡量，而衡量这些最有说服力的依据就是用户的使用数据，这些数据来源是刚才说的 按钮的点击次数，页面的停留时长 等等。 使用场景 分析用户App的使用情况当然是直接用数据说话，那么想知道某些按钮的点击次数，就一定需要App的开发人员去具体的按钮点击方法里面埋点才行，有的公司有自己的一套完整的统计埋点系统，有的公司是使用第三方统计，最终都是可以看到按钮的点击次数的，不管怎么样想知道按钮的点击必须要App的开发人员亲自去写代码埋点才行，而这篇文章主要讲的是 无码统计 按钮点击次数。也就是不需要开发介入，我们就能知道按钮的点击了，开发人员只要负责他的业务开发就行，下面是一张 传统埋点 统计和 灵动分析 统计，灵动是TalkingData的SDK无码统计的一个功能。 先大致讲下左边 传统 埋点统计流程 首先需要制定埋点需求、设计埋点方案，需求有了后就去找开发沟通，埋点需求的讨论，双方确认需求通过后，然后准备需求文档，开发再根据文档来写具体的埋点代码。 代码写完后，App打包给测试人员，测试人员进行测试，同时还要对埋点参数的数据安全审核，参数是否有包含公司敏感信息。 测试通过后就需要上线了，这个过程一般是开发人员去完成的。iOS需要提交到AppStore上，以前大家都知道，一个审核周期就是一两周，还有随时被拒的可能，现在虽然周期变短了，但审核也还是挺严格的（走快捷通道的除外）。Android需要在各个渠道上重新发布，也是很麻烦的。 如果前面几部都顺利完成了的话，接下来就等待用户更新了，如果埋点统计功能跟其它新功能一起上线的话，我们更新就有理由了，如果仅仅这一版仅仅只是埋点统计功能，那么让用户更新App的理由又是一件头疼的事情了，不管怎么样经常让用户更新App多少会对用户用些影响的。 最终的结果应该是部分用户更新了App，那么我们能统计到按钮点击的用户了就只是更新了App的这一部分用户了，而且他们更新的时间是不一样的，最终我们终于可以看需求上的埋点统计了。 再看看右边 灵动 统计流程 同样需要制定需求，但是需求方可以直接根据自己的需求去使用 灵动 了，使用了灵动就可以直接看按钮的点击率了，这个过程不需要开发介入，也不需要用户去更新App。 从这张图可以看出，不需要开发人员介入，可以开发成功，提高开发效率，而且埋点也很灵活，需求人员（可以是产品，也可以是运营）可以直接使用灵动，也不需要用户更新，那么数据反馈会比传统埋点快很多，使用了就可以立即生效，需求方的观察周期也缩短了，能更灵活的做出决策。 实现原理 上面大致介绍了下 灵动 能给我们解决什么问题，这里讲的是 灵动 是通过什么样的技术手段实现，这里可能对于开发人员来说更喜欢，大家先看一张灵动使用时的一个交互 这张图分成两部分看，先看上面，一个用户在操作Client和PC，Client和PC通讯是通过一个Wss的服务器建立的长连接，这是灵动调试时的一个交互。 也就是说，用户使用灵动分析时，需要一个安装自己App的移动设备，这个App必须要集成TalkingData的统计分析SDK才行，SDK初始化时的AppID是在TalkingData创建应用时分配的。另一端用户要打开TalkingData的灵动网页，在App启动的时候摇一摇手机，然后就可以建立一个wss的长连接了。用户就可以直接在网页上给按钮添加监听事件了，添加完成后，在手机上点击该按钮，网页上就会提示被点击，调试完成后点击全部生效，配置数据就会保存到下面https的服务器。 我们的所有用户在启动App的时候，都可以从https服务器里获取到这套配置，客户端根据这套配置找到具体的按钮，监听点击事件，当按钮被点击后，就可以统计到了。 接下来再看看灵动调试过程中数据是具体怎么进行数据交互的。 可以看到App客户端和Web端交互主要分为四部分：设备信息 、 App基本结构 、控件绑定配置 、按钮点击信息 ，设备信息 主要是用来确认设备是调试者的设备，因为其它的终端用户也可能会误触发调试，App基本结构是用来在Web上展示移动App的，然后在Web上绑定了控件，就会把控件绑定配置发送给客户端，客户端根据配置监听绑定，当终端用户点击控件后，客户端就会把按钮点击信息传给Web端，Web显示控件被点击。 再回头看看实现原理的第一张图片，调试完成数据就会从WSS的长连接服务器存储到HTTPS的服务器，此后其它终端用户只要在再次启动App就能获取到埋点配置了，SDK根据埋点配置去找到具体的控件(按钮)，监听点击，当用户点击控件时就可以调用自定义埋点的方法，之后的数据处理就跟自定义埋点是一样的原理了。 可能有同学会有疑问，所有的App每次启动的时候都会去获取埋点配置，是不是会很耗流量？ 答案是不会的，服务器在没有埋点配置的时候每次将获取不到信息，那么将不会有什么流量消耗。如果服务器有配置了，App才会有些流量消耗的，而且这些配置信息是经过压缩的，所以流量消耗也不大，App获取到了配置之后就会做本地缓存，服务器配置不变的情况下再次获取配置也不会有流量的消耗，只有在下一次运营人员修改了新的控件绑定时才会消耗一些流量。 所以整个无码统计对终端用户的流量的影响是很小的。 你也可以参考这套逻辑试试自己也部署这么一套无码统计，之后就不用再担心运营给的埋点统计需求了，让他们自己去用无码统计吧。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"技术","slug":"技术","permalink":"//xiaoshenmao.github.io/blog/tags/技术/"}]},{"title":"Git教程","date":"2016-07-12T16:00:00.000Z","path":"2016/07/13/2016-07-13-GitTutorial/","text":"介绍 Git是做项目的版本管理，你也可以称它们为版本管理工具。假如现在你有一个文件夹，里面可以是项目，也可以是你的个人笔记(如我这个博客)，或者是你的简历、毕业设计等等，都可以使用git来管理。 目前常用的版本控制器有Git和SVN，即使这两个你没有全用过，至少也会听过，我这里以Git为例，个人比较喜欢Git，你也可以看看这篇文章：为什么Git比SVN好。我使用的是Mac，Mac上没自带Git环境，但是作为iOS开发者，我安装Xcode的时候，Xcode里是有自带Git的，所以我不需要考虑怎么去安装Git了。 安装Git在Mac OS X上安装Git 提供两种方法参考： 1、通过homebrew安装Git，具体方法请参考homebrew的文档2、直接从AppStore安装Xcode，Xcode集成了Git，不过默认没有安装，你需要运行Xcode。 在Windows上安装Git 从https://git-for-windows.github.io 下载，然后按默认选项安装即可，安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 配置Git安装完成后，还需要最后一步设置，在命令行输入： $ git config –global user.name “Your Name” $ git config –global user.email “email@example.com” “Your Name”： 是每次提交时所显示的用户名，因为Git是分布式版本控制系统，当我们push到远端时，就需要区分每个提交记录具体是谁提交的，这个”Your Name”就是最好的区分。 “email@example.com”： 是你远端仓库的email –global：用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然我们也可以对某个仓库指定不同的用户名和Email地址。 开始使用-建立仓库：你在目标文件夹下使命令： git init （创建.git文件） 就会创建一个 .git 隐藏文件，相当于已经建立了一个本地仓库。 添加到暂存区： git add . （全部添加到暂存区） git commit -m ‘ first commit’ （提交暂存区的记录到本地仓库） 其它git branc 查看时如出现 (HEAD detached at analytics_v2) dev master 代表现在已经进入一个临时的HEAD，可以使用 git checkout -b temp 创建一个 temp branch，这样临时HEAD上修改的东西就不会被丢掉了。然后切换到 dev 分支上，在使用 git branch merge temp，就可以把 temp 分支上的代码合并到 dev 上了。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"工具","slug":"工具","permalink":"//xiaoshenmao.github.io/blog/tags/工具/"}]},{"title":"iOS开发迎来机器学习的春天---TensorFlow","date":"2016-07-06T16:00:00.000Z","path":"2016/07/07/2016-07-07-iOSMachineLearning_TensorFlow/","text":"人工智能、机器学习都已走进了我们的日常，尤其是愈演愈热的大数据更是跟我们的生活息息相关，做 人工智能、数据挖掘的人在其他人眼中感觉是很高大上的，总有一种遥不可及的感觉，在我司也经常会听到数据科学部的同事们提到 机器学习、数据挖掘 之类的词。但这些名词真的跟我们移动开发就没直接关系了吗？ 作为移动开发者来说，无时无刻不被这些名词狠狠地敲打着脆弱的内心。💢 💢 💢 何时才能够将机器学习、深度学习应用在移动端，敲响移动端机器学习工业化的大门呢？ 想象一下，某一天你身处一个完全陌生的环境，周围都是陌生的事物，而运行在iPhone的某个APP却对这个环境了如指掌，你要做的就是打开这个APP，输入你需要了解的事物，iPhone告诉你这个事物的信息，你也就没有了陌生事物了。世界就在眼前！如下图： 上面物体的识别准确率还是蛮不错的，基本识别出了键盘（49%的概率）、鼠标（46%的概率）和水杯（24%的概率）。 但是在某些事物的识别准确度方便却差强人意，比如下图： iPhone 6被识别成了iPod（59%的概率），而iPod的却是不怎么敢认（10%的概率）。想想最崩溃的估计是iPhone 6了，身价直接被降了好几个等级。 上面的例子来自于TensorFlow官方iOSDemo，暂且不评述TensorFlow的识别准确度如何，毕竟它还年轻，但是仅凭其识别能力的体现，也给机器学习在移动端的运用带来了无限的可能。 一、TensorFlow（简称TF） 去年，Google资深系统专家Jeff Dean在湾区机器学习大会上隆重介绍了其第二代深度学习系统TensorFlow，一时间网络上针对TensorFlow的文章铺天盖地，揭秘TensorFlow：Google开源到底开的是什么？、Google开源TensorFlow系统，这背后都有什么门道？、如何评价Google发布的第二代深度学习系统TensorFlow?等等文章，TensorFlow的燎原之火一直在燃烧蔓延着，其GitHub上的开源库在此文撰写时，也已经被star：27550，fork：11054了。🔥 🔥 🔥 🔥 🔥 不负众望，Google一直宣称平台移植性非常好的TensorFlow，终于在2016年6月27日，发布0.9版本，宣布移动端支持。TensorFlow v0.9 now available with improved mobile support( 有墙💢 )，同时也给出了移动端的Demo，对于代码为生的程序员，身处大数据处理为主导的TalkingData，也小试身手了一把，下载TensorFlow源码，查看编译指南，开始跳坑、填坑之路，也成就了此篇拙文的产生。 二、从TensorFlow到iOS静态库对于iOS平台下如何使用TensorFlow，TensorFlow给出了详细的编译脚本命令，详情请查看官方文档的命令。 第一步. 工具准备工欲善其事必先利其器，在开始编译工作之前，需要准备一些编译所必须的工具： Homebrew: Mac os x 上包管理工具，具体使用方法可参考Doc。 1$ /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" Homebrew安装好之后，依次安装三个辅助性编译工具： 123$ brew install libtool $ brew install autoconf $ brew install automake 三个工具的含义，请参考：https://en.wikipedia.org/wiki/GNU_Libtool 第二步. 克隆TensorFlowGoogle以Apache 2.0开源协议将TensorFlow开源在GitHub上，我们可以直接使用TensorFlow源码。 在任意你想存放TensorFlow源码的地方（建议不要放在桌面。^_^），clone项目。 1$ git clone https://github.com/tensorflow/tensorflow 第三步. 编译前准备 在TensorFlow的tensorflow/contrib/makefile/目录下，有很多可使用的编译脚本，其中build_all_ios.sh脚本专门用来一键编译TensorFlow iOS静态库。虽然可以直接使用此脚本进行一键编译，但是因为有墙，某些依赖需要提前做处理。 下载protobuf protobuf 是编译前唯一需要特殊处理的依赖库，点击下载，下载protobuf之后，解压，备用。 下载googlemock 虽然protobuf编译脚本autogen.sh中的googlemock链接地址https://googlemock.googlecode.com/files/gmock-1.7.0.zip无法直接下载到，但是细心的人会发现，在浏览器中输入https://googlemock.googlecode.com/地址后，会跳转到https://github.com/google/googlemock地址，google在GiHub上的仓库地址。而GitHub上的仓库，我们可以直接的下载，克隆等。 我们直接在GitHub上下载googlemock(点击下载)，下载完成后，修改压缩包名字为gmock-1.7.0.zip，修改后将此压缩包移至上一步protobuf文件夹目录下，备用。 修改下载依赖脚本，移除protobuf的下载 在tensorflow/contrib/makefile/目录下，download_dependencies.sh脚本用来下载相关依赖，打开此脚本文件，注释掉或者直接删掉git clone https://github.com/google/protobuf.git ${DOWNLOADS_DIR}/protobuf部分，目的是不让脚本去下载protobuf。 上面三步准备好后，接下来就进入静态库编译了。 第四步. 一键编译 前面已经知道在TensorFlow文件夹tensorflow/contrib/makefile/目录下的build_all_ios.sh脚本是用来编译iOS静态库的脚本，因此可以直接执行此脚本，开始静态库的编译工作了。 但是有一个问题大家可能会发现，由于编译TensorFlow需要用到protobuf，但是protobuf使我们自己手动下载的，该怎么让手动下载的protobuf能够直接让build_all_ios.sh脚本使用呢？ 答案是复制、粘贴。可能有些low，但是有效。执行命令 build_all_ios.sh之后，立即把之前手动下载的protobuf文件夹拷贝进tensorflow/contrib/makefile/downloads目录。（放心，你拷贝的速度会很快，不会影响编译的执行的。^_^） 1$ build_all_ios.sh 一切准备就绪，接下来就是静静的等待编译完成了。在Mac编译的过程中，建议插上电源，最好不要让设备休眠断电，也最好不要去干别的东西，出去溜达一圈，回来后就看到战果了。 编译完成之后，会在tensorflow/contrib/makefile/gen/目录下看到编译的结果，关于这些静态库该如何使用，自己的项目如何应用，请参考TensorFlow iOS Examples。 三、遇到的问题1、googlecode.com被墙了，需要翻墙！（目前测试挂了VPN也没用），这也是上面编译前准备为什么要那么做的原因。 1curl: (7) Failed to connect to googlemock.googlecode.com port 443: Operation timed out 解决： 请参考 『第三步. 编译前准备』。 2、没有Xcode。 1234xcrun: error: SDK \"iphoneos\" cannot be locatedxcrun: error: SDK \"iphoneos\" cannot be locatedxcrun: error: unable to lookup item 'PlatformPath' in SDK 'iphoneos'+ IPHONEOS_PLATFORM= 解决：安装Xcode，从上面报错的命令中可以看到，在编译静态库的过程中使用了xcrun，而此命令是xCode本身具有的能力。 3、你的Xcode版本不是7.3或以后，或者你有多个Xcode，而默认的安装路径版本不是7.3或以后。 ```error: Xcode 7.3.0 or later is required. exit 1```/ 解决：更新Xcode至最新版本，并且保证默认路径下是最新/版本。 如果Xcode是7.3，并且没有条件更新Xcode，你可以修改tensorflow/contrib/makefile/compile_ios_tensorflow.sh 里的REQUIRED_XCODE_VERSION=7.3.0，为REQUIRED_XCODE_VERSION=7.3。（这样修改，目前还不确定会不会带来一些其他影响，最好是升级你的Xcode） 四、参考链接 TensorFlow 中文社区 TensorFlow for Mobile Caffe、TensorFlow、MXnet三个开源库对比 如何评价Tensorflow和其它深度学习系统 深度学习框架大战正在进行，谁将夺取“深度学习工业标准”的荣耀？ 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"机器学习","slug":"机器学习","permalink":"//xiaoshenmao.github.io/blog/tags/机器学习/"}]},{"title":"机器学习入门（名词科普）","date":"2016-07-04T16:00:00.000Z","path":"2016/07/05/2016-07-05-MachineLearning_introduce/","text":"通用名词ML 名词解释： 机器学习(Machine Learning)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。 它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。 DL 名词解释： 深度学习（Deep Learning）是机器学习拉出的分支，它试图使用包含复杂结构或由多重非线性变换构成的多个处理层对数据进行高层抽象的算法。 深度学习是机器学习中表征学习方法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的矢量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是将用非监督式或半监督式的特征学习和分层特征提取的高效算法来替代手工获取特征。 CNN 名词解释： 卷积神经网络（Convolutional neural networks，简称CNNs）是一种深度的监督学习下的机器学习模型 算法名词KNN: 名词解释： 邻近算法，或者说K最近邻(kNN，k-NearestNeighbor)分类算法。 邻近算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。 kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。 SVM: 名词解释： 支持向量机（Support Vector Machine）。 在机器学习领域，支持向量机SVM(Support Vector Machine)是一个有监督的学习模型，通常用来进行模式识别、分类、以及回归分析。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"机器学习","slug":"机器学习","permalink":"//xiaoshenmao.github.io/blog/tags/机器学习/"}]},{"title":"开发常用工具","date":"2016-06-02T03:15:06.000Z","path":"2016/06/02/2016-06-02-Develop_Tool/","text":"工欲善其事必先利其器，选择一些好的工具可以成吨的提高自己的工作效率。 个人开发常用工具的收集 cmd Markdown 作业部落出版的Markdown编辑器 RESTClient 一个开源的客户端HTTP调试工具。 lantern 蓝灯,一款开源的翻墙工具。 Charles 青花瓷, 一款HTTP/HTTPS的抓包工具。 Charles 从入门到精通 Sublime 一款强大的IDE,支持Python、JS、JSON格式化等等…更重要的是Sublime支持的插件很多。 实用的sublime插件集合 文章配图网站 还在为文章配图而苦恼吗？点击店面的网站吧，各种各样的图片帮你丰富你的文章。 Gratisography gratisography 里面的图片每周都会更新，很多时尚流行的照片在里面，并且适合用在设计项目上。 ssyer国内的网站，不需要翻墙，速度很快，图片最全。完全免费的图片库。 Pixabay 不同类型的高清摄影照片。 UI设计网站作为一个开发者，自己写些小程序的时候经常会为没有UI而烦恼，下面就是一些UI设计网站，有新颖的UI界面设计，也有单独的UI元素，icon等。 UI中国 国内潮流的UI设计作品。 webdesigndev 国外网站设计文章，各种各样的资料看到你眼花缭乱。 dribbble 接触过设计的应该都知道，一个很好的UI设计平台。 flaticon 各种icon的设计，一定有你想想要的。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"工具","slug":"工具","permalink":"//xiaoshenmao.github.io/blog/tags/工具/"}]},{"title":"我们日常生活中的 iBeacon","date":"2016-04-06T03:25:06.000Z","path":"2016/04/06/2016-04-07-iBeacon/","text":"随着低功耗蓝牙的推出，iBeacon 的使用是越来越广泛了，如：微信的附近摇一摇功能，又或者是当你进入大型商场，一些店铺给你推送通知，VR 场景识别等等，这些表示 iBeacon 已经与我们的生活精密相连了。 简介： 概念： iBeacon 是 iOS7 后苹果出的一项新技术，支持蓝牙4.0(或以上)的 iOS 设备，工作方式是低功耗蓝牙（Bluetooth Low Energy），向周围发送自己特有的ID，一个 iBeacon 硬件设备在不做任何处理的情况下一般可使用两三年左右。 iBeacon 的形状多种多样，大致如下图。 目前哪些地方有 iBeacon： 1、微信摇一摇：使用微信的人应该都知道微信有一个 周边摇一摇 功能， 使用的就是 iBeacon 技术。 很多餐馆都部有 iBeacon 的点，如果你想验证直接监测微信的 iBeaconUUID：FDA50693-A4E2-4FB1-AFCF-C6EB07647825。 2、走进某个商场时，忽然手机里推出一个通知，也是使用 iBeacon 技术。 3、帝都的地跌站大部分也有微信 UUID 的 iBeacon 发射器，具体是用来做什么的还不是慢清楚。 4、iBeacon 还可实现地理围栏、室内定位等功能。 iBeacon 技术 Apple的 CoreLocation.frame 里把iBeacon封装成了一个 CLBeacon 类，CLBeacon 大致有下面几个属性组成：Major 、Minor 、 proximity 、 rssi 、 accuracy 。 开发者如何使用 iBeacopn?: 1、用户需要添加 CoreLocation.framework ，App 才具备定位的功能。 2、App 开发者需要开启定位功能需要配置：在 Xcode 的 info.plist 里面添加 NSLocationAlwaysUsageDescription(允许后台访问位置信息) 或 requestWhenInUseAuthorization(允许使用时访问位置信息) 字段。（iOS7后该添加了该字段应用才会弹出 `是否允许应用访问用户的位置信息）。 创建和注册一个beacon区域 123456789- (void)registerBeaconRegionWithUUID:(NSUUID *)proximityUUID andIdentifier:(NSString *)identifier&#123; CLBeaconRegion *beaconRegion = [[CLBeaconRegion alloc] initWithProximityUUID:proximityUUID identifier:identifier]; [manager startMonitoringForRegion:beaconRegion];&#125;``` 当接受到 iBeacon 信号时回调 ，beacons 里面装了信号的对象，可能同时出现多个信号。 (void)locationManager:(CLLocationManager )manager didRangeBeacons:(NSArray )beacons inRegion:(CLBeaconRegion *)region{ }``` Note: 苹果iBeacon官方代码例子。 iBeacon 硬件设备条件： 用户设备 iOS7 或更新操作系统。 用户蓝牙设备4.0或更新。 用户蓝牙设备必须开启。 用户设备定位服务必须开启，允许应用访问位置信息。 iBeacon 能唤醒应用 前提：App 具备上面使用 iBeacon 的功能，并且允许后台访问位置信息。 现象：App 能被 iBeacon 信号唤醒，即使 App 已经被用户手动杀死掉了，App 也能被 iBeacon 技术唤醒，并且能执行一系列操作。 影响：导致 App 用户在并没有使用 App 的情况下, App 有了长达几个小时的后台使用时长。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"技术","slug":"技术","permalink":"//xiaoshenmao.github.io/blog/tags/技术/"}]},{"title":"CocoaPods使用心得","date":"2016-04-01T16:00:00.000Z","path":"2016/04/02/2016-04-02-CocoaPod_Use/","text":"简介： 本章介绍什么是 CocoaPods ,如何使用 CocoaPods , 以及 CocoaPods 的原理,和使用 CocoaPods 时经常出现的一些问题。 Cocoapods 是 OS X 和 iOS 下的一个第三方库管理工具。我们能使用CocoaPods添加被称作 “Pods”的依赖库,并轻松管理它们的版本,CocoaPods会帮我们配置好这些三方库的路径及开发环境,极大的提升了开发者的工作效率。 安装CocoaPods Mac下自带ruby,使用ruby的gem命令安装,ruby的软件源被墙了,把官方的ruby源替换成国内的淘宝源。 更换Gem源123$ gem sources --remove https://rubygems.org/$ gem sources -a https://ruby.taobao.org/$ gem sources -l 1.移除掉原有的源（服务器在国外，速度较慢）。 2.等1有反应之后再敲2命令（替换成淘宝上的ruby镜像https）。 3.验证是否成功。成功如下： 1234*** CURRENT SOURCES ***http://ruby.taobao.org/ 更新Gem源12sudo gem update --system 安装cocoapods123$ sudo gem install cocoapods$ pod setup pod setup 在执行时会比较慢，因为Cocoapods 要将它的信息下载到 ~/.cocoapods目录下, 耐心等待… 提升cocoapods的安装速度所有的项目的 Podspec 文件都托管在https://github.com/CocoaPods/Specs。第一次执行 pod setup 时，CocoaPods 会将这些podspec索引文件更新到本地的 ~/.cocoapods/目录下，这个索引文件比较大，有 80M 左右。作者akinliu 在 gitcafe 和 oschina 上建立了 CocoaPods 索引库的镜像(在国内),我们可以使用CocoaPods国内的镜像索引，操作时会快多了,如gitcafe： 1234pod repo remove masterpod repo add master https://gitcafe.com/akuandev/Specs.gitpod repo update 使用cocoapodscocoapods安装完成后，使用 pod search 命令来验证一下 12pod search AFNetworking 终端将会有如下结果： 12345678910111213141516171819202122232425262728-&gt; AFNetworking (3.0.4)A delightful iOS and OS X networking framework.pod 'AFNetworking', '~&gt; 3.0.4'- Homepage: https://github.com/AFNetworking/AFNetworking- Source: https://github.com/AFNetworking/AFNetworking.git- Versions: 3.0.4, 3.0.3, 3.0.2, 3.0.1, 3.0.0, 3.0.0-beta.3, 3.0.0-beta.2,3.0.0-beta.1, 2.6.3, 2.6.2, 2.6.1, 2.6.0, 2.5.4, 2.5.3, 2.5.2, 2.5.1, 2.5.0,2.4.1, 2.4.0, 2.3.1, 2.3.0, 2.2.4, 2.2.3, 2.2.2, 2.2.1, 2.2.0, 2.1.0, 2.0.3,2.0.2, 2.0.1, 2.0.0, 2.0.0-RC3, 2.0.0-RC2, 2.0.0-RC1, 1.3.4, 1.3.3, 1.3.2,1.3.1, 1.3.0, 1.2.1, 1.2.0, 1.1.0, 1.0.1, 1.0, 1.0RC3, 1.0RC2, 1.0RC1,0.10.1, 0.10.0, 0.9.2, 0.9.1, 0.9.0, 0.7.0, 0.5.1 [master repo]- Subspecs:- AFNetworking/Serialization (3.0.4)- AFNetworking/Security (3.0.4)- AFNetworking/Reachability (3.0.4)- AFNetworking/NSURLSession (3.0.4)- AFNetworking/UIKit (3.0.4)-&gt; AFNetworking+AutoRetry (0.0.5)Auto Retries for AFNetworking requestspod 'AFNetworking+AutoRetry', '~&gt; 0.0.5'- Homepage: https://github.com/shaioz/AFNetworking-AutoRetry- Source: https://github.com/shaioz/AFNetworking-AutoRetry.git- Versions: 0.0.5, 0.0.4, 0.0.3, 0.0.2, 0.0.1 [master repo].........太多了，省略 pod search 是CocoaPods的一个搜索命令,我们可以用来搜索任何托管在CocoaPods上的三方库。 使用CocoaPods时需要新建一个 Podfile 的文件,cd 到 我的Demo项目里，Demo目录下有三个文件 12Demo 、 Demo.xcodeproj 、 DemoTests 新建 Podfile 12touch Podfile vim 编辑 Podfile 1vim Podfile 由于是新建的 Podfile 里面应该是空白的。然后我们在里面添加依赖库，格式如下： 1234platform :iospod 'Reachability', '~&gt; 3.0.0'pod 'ASIHTTPRequest' ‘~&gt; 3.0.0’ 是 Reachability 的版本号, 设定了版本号CocoaPods就会下载对应的版本,ASIHTTPRequest没指定版本号,CocoaPods就会下载最新版本的ASIHTTPRequest。退出编辑，执行 pod install 下载三方库。 12pod install 完成后我Demo项目下的文件多了几个: 123Demo 、 Demo.xcodeproj 、 DemoTests （之前的三个）Demo.xcworkspace 、Podfile 、Podfile.lock 、Pods 这个时候我们打开Demo项目是点击 Demo.xcworkspace 文件了，到此CocoaPods的基本使用已经讲完了，接下来的CocoaPods的原理，和让我们自己的三方库也支持CocoaPods。 待续… 深入理解 CocoaPods 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]},{"title":"iOS动态更新","date":"2016-01-09T03:15:06.000Z","path":"2016/01/09/2016-01-09-iOS_OTA/","text":"1、控件到 window 的层级关系: 2、分析控件的详细路径: 3、动态修改控件: 4、工具篇: 视图的层级关系每个 App , 至少有一个根 Window , 通常情况下我们只用一个 。window 有一个 rootViewController , 这就是我们所谓的根视图 , 我们所有的控制器都是放在 rootViewController 里面的。 如果在项目里有了这么一个路径 , 我们可以做什么呢？ 在当项目很复杂 , 可以其它地方可以直接修改这个控件的状态 当某个控件命名存在却又没有显示出来 , 可以通过路径来辅助查找 由服务器下发一些配置 , 使用 Runtime 去动态的修改已上线的项目 下面将介绍如何使用代码来找出这些视图(控件)的路径 分析控件的详细路径1、找出根 Window :每一个视图、控件 , 他们最终的根都是main函数返回的 application , 通过 [UIApplication sharedApplication] 可以得到 。 application 的 windows 属性是一个数组 , 这里面装的是这个应用的所有 Window , 我们通常用的是第一个也就是 application.windows[0] 2、遍历视图 :得到了 window 对象一切都好办了 。 然后拿到 window 的 rootViewController , 在获取 rootViewController 里面所有的 childViewControllers 和 view 里的 subviews , 一直递归下去就可以得到当前屏幕里所有视图对象了 , 同时可以通过 runtime 把它们的 property、delegate 都获取出来。 结合 Reveal 或者 Xcode 自带的 Captuer View Hiearachy , 我们可以推测一下这两个的的实现原理了 : 1、根据应用得到根视图2、递归获取里面的所有控件3、按照他们的层级关系一层一层的画出来 动态修改控件1、把上面获取到的所有控件的详细信息上传到服务器 。2、根据业务需求由服务器给我们下发对应的配置列表，以 button 为例 : 配置列表里必须要有 : 1)、button 的全路径 : 如 UIWindow -&gt; UIWindow -&gt; UIView -&gt; UIView -&gt; UILayoutContainerView -&gt; UITabBar -&gt; UIView —&gt; UIButton 2)、button 的唯一标识 : 如 tag 值或自己实现的一套算法生成的唯一标识 , 目的是防止与 button 同一层次的视图搞混 。 3)、 根据路径及唯一标识来匹配 App 里的控件 , 匹配和上面的查找原理是相通的。 4)、 匹配成功代表 button 确实存在 , 根据业务需求做后续操作 。 提示: 匹配策略尽可能的多 , 防止意外情况某一两个标识生成失败或者生成相同 。 3、修改 button 的状态。 1)、 如某个按钮点了会 Crash 或暂时不需要被点击 , 但是又要展示出来 , 可以直接修改 button 的 enabled 属性 。 2)、 如某业务暂时关闭 , 可以直接修改入口 按钮 frame为0 , 前提是要自动布局已做好 。 3)、 如给购买 按钮 添加监听事件 addTarget: action: forControlEvents: target 也可以通过上面 遍历视图 获取到 , action 可以由服务器下发 , 也可以一开始就写死 , 等有需求的时候直接传不同的参数就行了 。 4、 绑定查找控件时 , 这个界面必须要已经初始化完成了才行 , 假如界面还没生成肯定是查找不到这个控件的 。 这里给大家提供两种思路 : 1、使用Runtime Method Swizzing , 直接把修改控件的方法与 didMoveToSuperview 和 didMoveToWindow 动态绑定 , 等这个控件加载出来之后再去修改 , 查找路径正确的话肯定就能找到了 。 2、在具体的类里面 , 等控件的初始化方法调用完后 , 再去执行动态修改 , 如在viewDidLoad 里面初始化控件 , 在 viewWillAppear: 里面动态修改 。 建议使用第一种适用范围更强 。 上架后的 应用 可能会遇到的一些突发状况 , 未测出的Crash、临时改点小需求 , 等等 , 我们总不能每次因为一点小改动就重新提交一次 App Store , 先不说 App Store 的审核时间 , 频繁的让用户去更新应用 , 用户也会烦的 。使用这篇文章所讲的来实现动态更新是再合适不过了 。 首先上面讲的 动态更新 是完全脱离出来的一个模块 , 跟业务逻辑没有任何关系 , 只需要部署一次就行了 , 等开发下一个项目也可以直接拿过去使用 。这里的动态更新适用于局部的视图、控件的修改 , 如果你有其它需求可以考虑 JSPatch , 下发脚本也是一个不错的选择 。 工具篇使用一些UI调试的辅助工具 , 使我们查看视图在项目中得层次结构更为方便 。常用的UI调试的工具： Captuer View Hiearachy Reveal Xcode自带的 Captuer View Hiearachy 实现步骤: 1、打开Xcode , 运行项目 , 选择最顶部的 Debug 2、Debug -&gt; View Debugging -&gt; Show View Frames 3、Debug -&gt; View Debugging -&gt; Captuer View Hiearachy Xcode里面就变成了三维的视图了 , Xcode左侧展示出来的是层级关系的树状图 。 Reveal的功能相对来说更强大 , 适用于UI调试视图查找 。使用方法请看 Reveal集成指南 。 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]},{"title":"iOS 9 变化笔记","date":"2015-09-26T10:15:06.000Z","path":"2015/09/26/2015-09-26-iOS9_Note/","text":"这里将介绍下我们日常开发一些从iOS8过度到iOS9给我们带来的一些变化，及解决方法。 App Transport SecurityiOS9和OS X El Capitan的一个新特性，App Transport Security 的目地是提高Apple 操作系统的安全性以及在此操作系统上运行的任何应用的安全性。ATS是苹果针对与 NSURL这一层做的封装，iOS9后ATS默认是开启的，即网络传输需要使用HTTPS。如果想在iOS9后继续使用HTTP的话，有两条路可以走： 在Info.plist中添加 NSAppTransportSecurity类型Dictionary，在NSAppTransportSecurity下添加NSAllowsArbitraryLoads，Boolean 为 YES。 直接使用CFNetwork做网络请求，ASIHTTPRequest就是基于CFNetwotk做的封装，如果有需求的同学可以看看ASI里面的源码，如果某个时间段你又想要使用HTTPS的话，ASI对SSL/TSL的证书验证有点问题，证书验证还得自己封装一下才行。刚才我说道，ATS是苹果针对与NSURL这一层做的封装，所以我们使用CFNetwork或者更底层做网络请求的话是不受ATS限制的。 移除了discoveryd DNS解析服务iPhone升级到iOS8后WiFi有时候会有问题，特别是Mac升级到OS X Yosemite后，时而电脑休眠唤醒唬就连不上WiFi，有时候还突然掉线，经常要手动去关闭WiFi在重新连接，这是因为苹果到了OS X Yosemite系统后，把之前的mDNSResponder换成了discoveryd DNS。iOS9和OS X Yosemite10.4后mDNSResponder又回来了。 mDNSResponder： 苹果以前一直使用控制DNS和Bonjour服务的一种进程。discoveryd：OS X Yosemite后苹果新出的一种进程。 App ThinningApp Thinning是一个关于节省iOS设备存储空间的功能，它可以让iOS设备在安装、更新及运行App等场景中仅下载所需的资源，减少App的占用空间，从而节省设备的存储空间。 App Thinning主要有三个机制： Slicing： 开发者把App安装包上传到AppStore后，Apple服务会自动对安装包切割为不同的应用变体(App variant)， 当用户下载安装包时，系统会根据设备型号下载安装对应的单个应用变体。 On-Demand Resources： ORD(随需资源)是指开发者对资源添加标签上传后，系统会根据App运行的情况，动态下载并加载所需资源，而在存储空间不足时，自动删除这类资源。 Bitcode：开启Bitcode编译后，可以使得开发者上传App时只需上传Intermediate Representation(中间件)，而非最终的可执行二进制文件。 在用户下载App之前，AppStore会自动编译中间件，产生设备所需的执行文件供用户下载安装。 其中，Bitcode的机制可以支持动态的进行App Slicing，而对于Apple未来进行硬件升级的措施，此机制可以保证在开发者不重新发布版本的情况下而兼容新的设备。Xcode7默认是开始了Bitcode，如果不想使用可以手动关闭Bitcode： 选择项目——&gt;点击Target——&gt;点击Build Setttings——&gt;搜索栏里搜bitcode——&gt;把Enable Bitcode对应的Yes改成No。 启用Bitcode编译机制，需要注意以下几点： 如果应用开启Bitcode，那么其集成的其他第三方库也需要是Bitcode编译的包才能真正进行Bitcode编译 开启Bitcode编译后，编译产生的.app体积会变大(中间代码，不是用户下载的包)，且.dSYM文件不能用来崩溃日志的符号化（用户下载的包是Apple服务重新编译产生的，有产生新的符号文件），使用dSYM来收集Crash日志的同学得注意了。 通过Archive方式上传AppStore的包，可以在Xcode的Organizer工具中下载对应安装包的新的符号文件 后台定位iOS9后苹果为了对保障用户的地理位置的隐私对App请求后台定位有了权限设置，则需要多加一些代码。如果不适配iOS9，就不能偷偷在后台定位，如果没有后台定位的权限也是可以在后台定位的，只是会出现蓝条。 开启后台定位功能：locationManager.allowsBackgroundLocationUpdates = YES;locationManager是CLLocationManager的对象，用来管理整个定位的。 重点： 配置info.plist，添加一个Required background modes，Array类型的，然后在Required background modes里面Item 0对应的Value设置为App registers for location updates，这样就解决了iOS9后台定位出现蓝条的问题了。 UI TestingXcode7中苹果引入了一种新的方式在应用中进行测试——UI Testting，UI Testting允许我们找到UI元素与之交互，还能检查属性和状态。UI Testting已经完全集成进了Xcode7的测试报告，可以和单元测试一起执行。使用起来跟之前Xcode5出来的XCTest差不多，Xcode bots提供对此的支持，而且command line支持当UI测试失败时会立即发出通知。 可以参考Github上的Demo，步骤： 在DemoTests.m里创建一个test开头的方法 在setUp()里启动应用 XCUIApplication().launch() 新建一个方法test开头的，在里面获取应用let app = XCUIApplication() 的到let app = XCUIApplication()，app.buttons[“View Detail”].tap()?。buttons是当前这个界面的所有按钮的集合，[]里面写按钮的名字，tap()就是执行这个按钮所对应的方法，可以是网络请求、界面跳转等等。 URL scheme在iOS9中，如果使用URL scheme必须在”Info.plist”中将你要在外部调用的URL scheme列为白名单，否则不能使用。 配置info.plist，添加一个LSApplicationQueriesSchemes，Array类型的，然后在LSApplicationQueriesSchemes的Item里面添加urlscheme就行了，urlscheme是任意一个字符串，就是你自己需要使用的urlscheme，iOS9 URL scheme白名单适配就完成了。 出现大量的警告Xcode7后运行以前的项目后出现大量的警告如： 1(null): warning: /var/folders/p4/z7zy68r92hd3p5ry5g2v3k_8rlwzzr/C/org.llvm.clang.dalmo/ModuleCache/1TXZDLI9N2EMV/Foundation-3DFYNEBRQSXST.pcm: No such file or directory。 作为一个有洁癖的我反正是不能忍，出现警告的大致原因跟我上面提到的开启Bitcode，.dSYM文件不能用来符号化有关，Xcode试图去创建dSYM文件，但是你又不需要。 解决方法 Build Settings ——&gt;Build Options——&gt;Debug Information Format Debug下的DWARF with dsYM File改成DWARF Release下的还是之前默认的DWARF with dsYM File不变 参考资料： iOS9AdaptationTips iOS9学习系列 iOS9-day-by-day 转载请注明：xiaoshenmao的博客 » 点击阅读原文","tags":[{"name":"iOS","slug":"iOS","permalink":"//xiaoshenmao.github.io/blog/tags/iOS/"}]}]